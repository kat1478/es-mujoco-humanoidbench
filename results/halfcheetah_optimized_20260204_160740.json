{
  "experiment": "halfcheetah_optimized",
  "config": {
    "env_name": "HalfCheetah-v4",
    "population_size": 40,
    "sigma": 0.02,
    "learning_rate": 0.01,
    "max_episode_steps": 400,
    "seed": 42
  },
  "results": {
    "final_reward_mean": 132.21045631326885,
    "final_reward_std": 60.143881412039626,
    "best_reward": 483.61785888671875,
    "total_timesteps": 1008000,
    "total_iterations": 63,
    "total_time_seconds": 252.7310574054718
  },
  "history": [
    {
      "iteration": 1,
      "timesteps": 16000,
      "mean_reward": -187.30465698242188,
      "max_reward": -71.34563446044922,
      "min_reward": -365.29339599609375,
      "std_reward": 76.11007690429688,
      "best_reward": -187.30465698242188,
      "episodes": 40,
      "steps_this_iter": 16000
    },
    {
      "iteration": 2,
      "timesteps": 32000,
      "mean_reward": -53.37816619873047,
      "max_reward": 111.20994567871094,
      "min_reward": -186.5286102294922,
      "std_reward": 54.39631271362305,
      "best_reward": -53.37816619873047,
      "episodes": 40,
      "steps_this_iter": 16000
    },
    {
      "iteration": 3,
      "timesteps": 48000,
      "mean_reward": -42.32100296020508,
      "max_reward": 61.16664505004883,
      "min_reward": -187.78762817382812,
      "std_reward": 60.32090377807617,
      "best_reward": -42.32100296020508,
      "episodes": 40,
      "steps_this_iter": 16000
    },
    {
      "iteration": 4,
      "timesteps": 64000,
      "mean_reward": -69.07085418701172,
      "max_reward": 50.04313278198242,
      "min_reward": -193.50758361816406,
      "std_reward": 61.180545806884766,
      "best_reward": -42.32100296020508,
      "episodes": 40,
      "steps_this_iter": 16000
    },
    {
      "iteration": 5,
      "timesteps": 80000,
      "mean_reward": -2.104198694229126,
      "max_reward": 88.95856475830078,
      "min_reward": -131.00430297851562,
      "std_reward": 46.32750701904297,
      "best_reward": -2.104198694229126,
      "episodes": 40,
      "steps_this_iter": 16000
    },
    {
      "iteration": 6,
      "timesteps": 96000,
      "mean_reward": -34.71366500854492,
      "max_reward": 118.67884826660156,
      "min_reward": -178.03164672851562,
      "std_reward": 76.50979614257812,
      "best_reward": -2.104198694229126,
      "episodes": 40,
      "steps_this_iter": 16000
    },
    {
      "iteration": 7,
      "timesteps": 112000,
      "mean_reward": 47.7204475402832,
      "max_reward": 196.38201904296875,
      "min_reward": -218.1853485107422,
      "std_reward": 80.69921875,
      "best_reward": 47.7204475402832,
      "episodes": 40,
      "steps_this_iter": 16000
    },
    {
      "iteration": 8,
      "timesteps": 128000,
      "mean_reward": 47.58385467529297,
      "max_reward": 241.60125732421875,
      "min_reward": -137.1116943359375,
      "std_reward": 88.36866760253906,
      "best_reward": 47.7204475402832,
      "episodes": 40,
      "steps_this_iter": 16000
    },
    {
      "iteration": 9,
      "timesteps": 144000,
      "mean_reward": 43.26486587524414,
      "max_reward": 269.53594970703125,
      "min_reward": -103.88047790527344,
      "std_reward": 96.05653381347656,
      "best_reward": 47.7204475402832,
      "episodes": 40,
      "steps_this_iter": 16000
    },
    {
      "iteration": 10,
      "timesteps": 160000,
      "mean_reward": 99.1368408203125,
      "max_reward": 281.87518310546875,
      "min_reward": -89.23832702636719,
      "std_reward": 103.51139068603516,
      "best_reward": 99.1368408203125,
      "episodes": 40,
      "steps_this_iter": 16000
    },
    {
      "iteration": 11,
      "timesteps": 176000,
      "mean_reward": 112.40177917480469,
      "max_reward": 398.00653076171875,
      "min_reward": -71.32555389404297,
      "std_reward": 110.52208709716797,
      "best_reward": 112.40177917480469,
      "episodes": 40,
      "steps_this_iter": 16000
    },
    {
      "iteration": 12,
      "timesteps": 192000,
      "mean_reward": -76.81166076660156,
      "max_reward": 408.0639343261719,
      "min_reward": -210.7652130126953,
      "std_reward": 125.38394165039062,
      "best_reward": 112.40177917480469,
      "episodes": 40,
      "steps_this_iter": 16000
    },
    {
      "iteration": 13,
      "timesteps": 208000,
      "mean_reward": 115.8554458618164,
      "max_reward": 249.22152709960938,
      "min_reward": -96.93209075927734,
      "std_reward": 81.4244155883789,
      "best_reward": 115.8554458618164,
      "episodes": 40,
      "steps_this_iter": 16000
    },
    {
      "iteration": 14,
      "timesteps": 224000,
      "mean_reward": 50.280311584472656,
      "max_reward": 227.10504150390625,
      "min_reward": -165.9405975341797,
      "std_reward": 99.25593566894531,
      "best_reward": 115.8554458618164,
      "episodes": 40,
      "steps_this_iter": 16000
    },
    {
      "iteration": 15,
      "timesteps": 240000,
      "mean_reward": 91.77745056152344,
      "max_reward": 188.11146545410156,
      "min_reward": -32.76059341430664,
      "std_reward": 53.30328369140625,
      "best_reward": 115.8554458618164,
      "episodes": 40,
      "steps_this_iter": 16000
    },
    {
      "iteration": 16,
      "timesteps": 256000,
      "mean_reward": -6.021685600280762,
      "max_reward": 200.3837890625,
      "min_reward": -146.83673095703125,
      "std_reward": 82.85577392578125,
      "best_reward": 115.8554458618164,
      "episodes": 40,
      "steps_this_iter": 16000
    },
    {
      "iteration": 17,
      "timesteps": 272000,
      "mean_reward": -70.31859588623047,
      "max_reward": 131.9092254638672,
      "min_reward": -216.04486083984375,
      "std_reward": 70.88472747802734,
      "best_reward": 115.8554458618164,
      "episodes": 40,
      "steps_this_iter": 16000
    },
    {
      "iteration": 18,
      "timesteps": 288000,
      "mean_reward": 137.9761505126953,
      "max_reward": 264.5667724609375,
      "min_reward": -216.50035095214844,
      "std_reward": 104.4137191772461,
      "best_reward": 137.9761505126953,
      "episodes": 40,
      "steps_this_iter": 16000
    },
    {
      "iteration": 19,
      "timesteps": 304000,
      "mean_reward": 73.05110931396484,
      "max_reward": 224.18081665039062,
      "min_reward": -97.79204559326172,
      "std_reward": 92.70652770996094,
      "best_reward": 137.9761505126953,
      "episodes": 40,
      "steps_this_iter": 16000
    },
    {
      "iteration": 20,
      "timesteps": 320000,
      "mean_reward": 66.38985443115234,
      "max_reward": 240.3126220703125,
      "min_reward": -136.35682678222656,
      "std_reward": 105.70633697509766,
      "best_reward": 137.9761505126953,
      "episodes": 40,
      "steps_this_iter": 16000
    },
    {
      "iteration": 21,
      "timesteps": 336000,
      "mean_reward": 66.25971984863281,
      "max_reward": 207.21224975585938,
      "min_reward": -175.27496337890625,
      "std_reward": 93.89781188964844,
      "best_reward": 137.9761505126953,
      "episodes": 40,
      "steps_this_iter": 16000
    },
    {
      "iteration": 22,
      "timesteps": 352000,
      "mean_reward": 74.56534576416016,
      "max_reward": 203.56832885742188,
      "min_reward": -198.94313049316406,
      "std_reward": 85.92518615722656,
      "best_reward": 137.9761505126953,
      "episodes": 40,
      "steps_this_iter": 16000
    },
    {
      "iteration": 23,
      "timesteps": 368000,
      "mean_reward": 111.1424560546875,
      "max_reward": 256.55902099609375,
      "min_reward": -172.86741638183594,
      "std_reward": 91.37208557128906,
      "best_reward": 137.9761505126953,
      "episodes": 40,
      "steps_this_iter": 16000
    },
    {
      "iteration": 24,
      "timesteps": 384000,
      "mean_reward": 32.07091522216797,
      "max_reward": 148.07379150390625,
      "min_reward": -218.4904022216797,
      "std_reward": 92.22633361816406,
      "best_reward": 137.9761505126953,
      "episodes": 40,
      "steps_this_iter": 16000
    },
    {
      "iteration": 25,
      "timesteps": 400000,
      "mean_reward": 116.67620849609375,
      "max_reward": 244.16940307617188,
      "min_reward": -101.50199127197266,
      "std_reward": 77.3216323852539,
      "best_reward": 137.9761505126953,
      "episodes": 40,
      "steps_this_iter": 16000
    },
    {
      "iteration": 26,
      "timesteps": 416000,
      "mean_reward": 205.3327178955078,
      "max_reward": 350.581787109375,
      "min_reward": -33.243133544921875,
      "std_reward": 89.09193420410156,
      "best_reward": 205.3327178955078,
      "episodes": 40,
      "steps_this_iter": 16000
    },
    {
      "iteration": 27,
      "timesteps": 432000,
      "mean_reward": 168.07510375976562,
      "max_reward": 372.6226806640625,
      "min_reward": -213.14108276367188,
      "std_reward": 116.53338623046875,
      "best_reward": 205.3327178955078,
      "episodes": 40,
      "steps_this_iter": 16000
    },
    {
      "iteration": 28,
      "timesteps": 448000,
      "mean_reward": 198.1510467529297,
      "max_reward": 333.2892150878906,
      "min_reward": -37.95338821411133,
      "std_reward": 76.84073638916016,
      "best_reward": 205.3327178955078,
      "episodes": 40,
      "steps_this_iter": 16000
    },
    {
      "iteration": 29,
      "timesteps": 464000,
      "mean_reward": 237.2459716796875,
      "max_reward": 327.9168701171875,
      "min_reward": -64.3521957397461,
      "std_reward": 72.1457748413086,
      "best_reward": 237.2459716796875,
      "episodes": 40,
      "steps_this_iter": 16000
    },
    {
      "iteration": 30,
      "timesteps": 480000,
      "mean_reward": 283.89849853515625,
      "max_reward": 413.1732177734375,
      "min_reward": 143.5981903076172,
      "std_reward": 70.90094757080078,
      "best_reward": 283.89849853515625,
      "episodes": 40,
      "steps_this_iter": 16000
    },
    {
      "iteration": 31,
      "timesteps": 496000,
      "mean_reward": 305.65753173828125,
      "max_reward": 439.7174072265625,
      "min_reward": 121.95848083496094,
      "std_reward": 86.14080047607422,
      "best_reward": 305.65753173828125,
      "episodes": 40,
      "steps_this_iter": 16000
    },
    {
      "iteration": 32,
      "timesteps": 512000,
      "mean_reward": 366.12811279296875,
      "max_reward": 562.41162109375,
      "min_reward": -79.73843383789062,
      "std_reward": 117.49691772460938,
      "best_reward": 366.12811279296875,
      "episodes": 40,
      "steps_this_iter": 16000
    },
    {
      "iteration": 33,
      "timesteps": 528000,
      "mean_reward": 328.8143615722656,
      "max_reward": 507.746826171875,
      "min_reward": 101.78009796142578,
      "std_reward": 97.56573486328125,
      "best_reward": 366.12811279296875,
      "episodes": 40,
      "steps_this_iter": 16000
    },
    {
      "iteration": 34,
      "timesteps": 544000,
      "mean_reward": 288.9391174316406,
      "max_reward": 629.715087890625,
      "min_reward": -153.02830505371094,
      "std_reward": 142.6133270263672,
      "best_reward": 366.12811279296875,
      "episodes": 40,
      "steps_this_iter": 16000
    },
    {
      "iteration": 35,
      "timesteps": 560000,
      "mean_reward": 299.3431701660156,
      "max_reward": 594.2717895507812,
      "min_reward": 66.42259216308594,
      "std_reward": 116.20162963867188,
      "best_reward": 366.12811279296875,
      "episodes": 40,
      "steps_this_iter": 16000
    },
    {
      "iteration": 36,
      "timesteps": 576000,
      "mean_reward": 354.57513427734375,
      "max_reward": 541.268798828125,
      "min_reward": 136.96261596679688,
      "std_reward": 86.2919692993164,
      "best_reward": 366.12811279296875,
      "episodes": 40,
      "steps_this_iter": 16000
    },
    {
      "iteration": 37,
      "timesteps": 592000,
      "mean_reward": 263.92926025390625,
      "max_reward": 446.3584899902344,
      "min_reward": 17.519126892089844,
      "std_reward": 90.2369384765625,
      "best_reward": 366.12811279296875,
      "episodes": 40,
      "steps_this_iter": 16000
    },
    {
      "iteration": 38,
      "timesteps": 608000,
      "mean_reward": 298.9879455566406,
      "max_reward": 611.0962524414062,
      "min_reward": -75.62054443359375,
      "std_reward": 172.87863159179688,
      "best_reward": 366.12811279296875,
      "episodes": 40,
      "steps_this_iter": 16000
    },
    {
      "iteration": 39,
      "timesteps": 624000,
      "mean_reward": 231.73690795898438,
      "max_reward": 446.7696533203125,
      "min_reward": -175.10443115234375,
      "std_reward": 141.32192993164062,
      "best_reward": 366.12811279296875,
      "episodes": 40,
      "steps_this_iter": 16000
    },
    {
      "iteration": 40,
      "timesteps": 640000,
      "mean_reward": 246.4215087890625,
      "max_reward": 541.6337280273438,
      "min_reward": -146.62985229492188,
      "std_reward": 143.0259552001953,
      "best_reward": 366.12811279296875,
      "episodes": 40,
      "steps_this_iter": 16000
    },
    {
      "iteration": 41,
      "timesteps": 656000,
      "mean_reward": 255.5809326171875,
      "max_reward": 437.3402404785156,
      "min_reward": -41.308536529541016,
      "std_reward": 102.1445083618164,
      "best_reward": 366.12811279296875,
      "episodes": 40,
      "steps_this_iter": 16000
    },
    {
      "iteration": 42,
      "timesteps": 672000,
      "mean_reward": 343.26025390625,
      "max_reward": 575.5923461914062,
      "min_reward": 21.782917022705078,
      "std_reward": 118.68181610107422,
      "best_reward": 366.12811279296875,
      "episodes": 40,
      "steps_this_iter": 16000
    },
    {
      "iteration": 43,
      "timesteps": 688000,
      "mean_reward": 389.90692138671875,
      "max_reward": 608.9046630859375,
      "min_reward": -121.98673248291016,
      "std_reward": 132.6907501220703,
      "best_reward": 389.90692138671875,
      "episodes": 40,
      "steps_this_iter": 16000
    },
    {
      "iteration": 44,
      "timesteps": 704000,
      "mean_reward": 312.703369140625,
      "max_reward": 476.0859680175781,
      "min_reward": -15.7076997756958,
      "std_reward": 97.5682373046875,
      "best_reward": 389.90692138671875,
      "episodes": 40,
      "steps_this_iter": 16000
    },
    {
      "iteration": 45,
      "timesteps": 720000,
      "mean_reward": 483.61785888671875,
      "max_reward": 639.59716796875,
      "min_reward": 321.1728515625,
      "std_reward": 75.91542053222656,
      "best_reward": 483.61785888671875,
      "episodes": 40,
      "steps_this_iter": 16000
    },
    {
      "iteration": 46,
      "timesteps": 736000,
      "mean_reward": 406.46661376953125,
      "max_reward": 627.7390747070312,
      "min_reward": -75.30628967285156,
      "std_reward": 139.01791381835938,
      "best_reward": 483.61785888671875,
      "episodes": 40,
      "steps_this_iter": 16000
    },
    {
      "iteration": 47,
      "timesteps": 752000,
      "mean_reward": 401.19659423828125,
      "max_reward": 556.6348876953125,
      "min_reward": 203.14874267578125,
      "std_reward": 84.01382446289062,
      "best_reward": 483.61785888671875,
      "episodes": 40,
      "steps_this_iter": 16000
    },
    {
      "iteration": 48,
      "timesteps": 768000,
      "mean_reward": 381.48101806640625,
      "max_reward": 609.73828125,
      "min_reward": -93.38154602050781,
      "std_reward": 128.6536865234375,
      "best_reward": 483.61785888671875,
      "episodes": 40,
      "steps_this_iter": 16000
    },
    {
      "iteration": 49,
      "timesteps": 784000,
      "mean_reward": 333.22698974609375,
      "max_reward": 530.6055297851562,
      "min_reward": 69.0510482788086,
      "std_reward": 104.32965850830078,
      "best_reward": 483.61785888671875,
      "episodes": 40,
      "steps_this_iter": 16000
    },
    {
      "iteration": 50,
      "timesteps": 800000,
      "mean_reward": 355.0884704589844,
      "max_reward": 570.4619140625,
      "min_reward": 115.70536041259766,
      "std_reward": 114.27635955810547,
      "best_reward": 483.61785888671875,
      "episodes": 40,
      "steps_this_iter": 16000
    },
    {
      "iteration": 51,
      "timesteps": 816000,
      "mean_reward": 410.3248596191406,
      "max_reward": 577.8566284179688,
      "min_reward": 230.6064910888672,
      "std_reward": 99.10562896728516,
      "best_reward": 483.61785888671875,
      "episodes": 40,
      "steps_this_iter": 16000
    },
    {
      "iteration": 52,
      "timesteps": 832000,
      "mean_reward": 328.7853698730469,
      "max_reward": 605.64306640625,
      "min_reward": -126.2329330444336,
      "std_reward": 211.10556030273438,
      "best_reward": 483.61785888671875,
      "episodes": 40,
      "steps_this_iter": 16000
    },
    {
      "iteration": 53,
      "timesteps": 848000,
      "mean_reward": 380.55108642578125,
      "max_reward": 575.8221435546875,
      "min_reward": -9.177010536193848,
      "std_reward": 131.95082092285156,
      "best_reward": 483.61785888671875,
      "episodes": 40,
      "steps_this_iter": 16000
    },
    {
      "iteration": 54,
      "timesteps": 864000,
      "mean_reward": 347.8943786621094,
      "max_reward": 559.8148193359375,
      "min_reward": -203.91969299316406,
      "std_reward": 159.36363220214844,
      "best_reward": 483.61785888671875,
      "episodes": 40,
      "steps_this_iter": 16000
    },
    {
      "iteration": 55,
      "timesteps": 880000,
      "mean_reward": 282.3716735839844,
      "max_reward": 554.8108520507812,
      "min_reward": -173.19342041015625,
      "std_reward": 161.52500915527344,
      "best_reward": 483.61785888671875,
      "episodes": 40,
      "steps_this_iter": 16000
    },
    {
      "iteration": 56,
      "timesteps": 896000,
      "mean_reward": 228.8735809326172,
      "max_reward": 489.0310974121094,
      "min_reward": -141.24569702148438,
      "std_reward": 166.79542541503906,
      "best_reward": 483.61785888671875,
      "episodes": 40,
      "steps_this_iter": 16000
    },
    {
      "iteration": 57,
      "timesteps": 912000,
      "mean_reward": 172.6502227783203,
      "max_reward": 464.4516906738281,
      "min_reward": -81.44610595703125,
      "std_reward": 145.81451416015625,
      "best_reward": 483.61785888671875,
      "episodes": 40,
      "steps_this_iter": 16000
    },
    {
      "iteration": 58,
      "timesteps": 928000,
      "mean_reward": 165.0856170654297,
      "max_reward": 419.58795166015625,
      "min_reward": -196.7254180908203,
      "std_reward": 143.6180877685547,
      "best_reward": 483.61785888671875,
      "episodes": 40,
      "steps_this_iter": 16000
    },
    {
      "iteration": 59,
      "timesteps": 944000,
      "mean_reward": 136.84927368164062,
      "max_reward": 372.2576904296875,
      "min_reward": -180.03012084960938,
      "std_reward": 126.19068908691406,
      "best_reward": 483.61785888671875,
      "episodes": 40,
      "steps_this_iter": 16000
    },
    {
      "iteration": 60,
      "timesteps": 960000,
      "mean_reward": 112.1478271484375,
      "max_reward": 324.0294494628906,
      "min_reward": -184.18214416503906,
      "std_reward": 134.30796813964844,
      "best_reward": 483.61785888671875,
      "episodes": 40,
      "steps_this_iter": 16000
    },
    {
      "iteration": 61,
      "timesteps": 976000,
      "mean_reward": 100.30128479003906,
      "max_reward": 254.70997619628906,
      "min_reward": -216.53372192382812,
      "std_reward": 114.96524047851562,
      "best_reward": 483.61785888671875,
      "episodes": 40,
      "steps_this_iter": 16000
    },
    {
      "iteration": 62,
      "timesteps": 992000,
      "mean_reward": 72.06340026855469,
      "max_reward": 289.35302734375,
      "min_reward": -216.4014129638672,
      "std_reward": 116.14620208740234,
      "best_reward": 483.61785888671875,
      "episodes": 40,
      "steps_this_iter": 16000
    },
    {
      "iteration": 63,
      "timesteps": 1008000,
      "mean_reward": 86.03516387939453,
      "max_reward": 265.728515625,
      "min_reward": -180.5148162841797,
      "std_reward": 102.68267059326172,
      "best_reward": 483.61785888671875,
      "episodes": 40,
      "steps_this_iter": 16000
    }
  ],
  "eval_history": [
    {
      "iteration": 50,
      "timesteps": 800000,
      "eval_reward": 382.2373758526838
    }
  ]
}