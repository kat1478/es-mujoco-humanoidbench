{
  "experiment": "h1hand-walk-v0",
  "config": {
    "env_name": "h1hand-walk-v0",
    "population_size": 40,
    "sigma": 0.02,
    "learning_rate": 0.01,
    "max_episode_steps": 1000,
    "seed": 42
  },
  "results": {
    "final_reward_mean": 7.724070270532818,
    "final_reward_std": 2.6173512283639826,
    "best_reward": 9.042348861694336,
    "total_timesteps": 1001551,
    "total_iterations": 338,
    "total_time_seconds": 4970.21205663681
  },
  "history": [
    {
      "iteration": 1,
      "timesteps": 3143,
      "mean_reward": 6.395426273345947,
      "max_reward": 42.883365631103516,
      "min_reward": 1.7750942707061768,
      "std_reward": 6.61790657043457,
      "best_reward": 6.395426273345947,
      "episodes": 40,
      "steps_this_iter": 3143
    },
    {
      "iteration": 2,
      "timesteps": 6568,
      "mean_reward": 5.861597537994385,
      "max_reward": 19.75112533569336,
      "min_reward": 1.6815593242645264,
      "std_reward": 3.69563627243042,
      "best_reward": 6.395426273345947,
      "episodes": 40,
      "steps_this_iter": 3425
    },
    {
      "iteration": 3,
      "timesteps": 10346,
      "mean_reward": 5.620343208312988,
      "max_reward": 14.088193893432617,
      "min_reward": 1.7921853065490723,
      "std_reward": 2.682816982269287,
      "best_reward": 6.395426273345947,
      "episodes": 40,
      "steps_this_iter": 3778
    },
    {
      "iteration": 4,
      "timesteps": 13514,
      "mean_reward": 5.141534805297852,
      "max_reward": 10.233211517333984,
      "min_reward": 2.4061543941497803,
      "std_reward": 1.9289345741271973,
      "best_reward": 6.395426273345947,
      "episodes": 40,
      "steps_this_iter": 3168
    },
    {
      "iteration": 5,
      "timesteps": 15678,
      "mean_reward": 5.31346321105957,
      "max_reward": 10.27924633026123,
      "min_reward": 3.170126438140869,
      "std_reward": 1.3802950382232666,
      "best_reward": 6.395426273345947,
      "episodes": 40,
      "steps_this_iter": 2164
    },
    {
      "iteration": 6,
      "timesteps": 19106,
      "mean_reward": 6.548170566558838,
      "max_reward": 15.373783111572266,
      "min_reward": 3.1640920639038086,
      "std_reward": 1.8167245388031006,
      "best_reward": 6.548170566558838,
      "episodes": 40,
      "steps_this_iter": 3428
    },
    {
      "iteration": 7,
      "timesteps": 21738,
      "mean_reward": 6.528739929199219,
      "max_reward": 9.211679458618164,
      "min_reward": 4.797149181365967,
      "std_reward": 0.8872944712638855,
      "best_reward": 6.548170566558838,
      "episodes": 40,
      "steps_this_iter": 2632
    },
    {
      "iteration": 8,
      "timesteps": 24855,
      "mean_reward": 6.325343132019043,
      "max_reward": 12.050326347351074,
      "min_reward": 3.64493465423584,
      "std_reward": 2.163921356201172,
      "best_reward": 6.548170566558838,
      "episodes": 40,
      "steps_this_iter": 3117
    },
    {
      "iteration": 9,
      "timesteps": 26829,
      "mean_reward": 5.682599067687988,
      "max_reward": 7.954704761505127,
      "min_reward": 4.610022068023682,
      "std_reward": 0.7009486556053162,
      "best_reward": 6.548170566558838,
      "episodes": 40,
      "steps_this_iter": 1974
    },
    {
      "iteration": 10,
      "timesteps": 28873,
      "mean_reward": 6.335092067718506,
      "max_reward": 11.395075798034668,
      "min_reward": 5.458748817443848,
      "std_reward": 1.0774335861206055,
      "best_reward": 6.548170566558838,
      "episodes": 40,
      "steps_this_iter": 2044
    },
    {
      "iteration": 11,
      "timesteps": 31317,
      "mean_reward": 5.939841270446777,
      "max_reward": 7.240258693695068,
      "min_reward": 5.206987380981445,
      "std_reward": 0.5322780609130859,
      "best_reward": 6.548170566558838,
      "episodes": 40,
      "steps_this_iter": 2444
    },
    {
      "iteration": 12,
      "timesteps": 34512,
      "mean_reward": 6.263158798217773,
      "max_reward": 7.811513423919678,
      "min_reward": 4.504806041717529,
      "std_reward": 0.7653142809867859,
      "best_reward": 6.548170566558838,
      "episodes": 40,
      "steps_this_iter": 3195
    },
    {
      "iteration": 13,
      "timesteps": 37838,
      "mean_reward": 6.319066524505615,
      "max_reward": 23.665441513061523,
      "min_reward": 3.5798444747924805,
      "std_reward": 3.3012101650238037,
      "best_reward": 6.548170566558838,
      "episodes": 40,
      "steps_this_iter": 3326
    },
    {
      "iteration": 14,
      "timesteps": 41021,
      "mean_reward": 7.147627353668213,
      "max_reward": 14.85453987121582,
      "min_reward": 4.305060863494873,
      "std_reward": 2.242199420928955,
      "best_reward": 7.147627353668213,
      "episodes": 40,
      "steps_this_iter": 3183
    },
    {
      "iteration": 15,
      "timesteps": 43716,
      "mean_reward": 6.0234880447387695,
      "max_reward": 14.243779182434082,
      "min_reward": 3.9034411907196045,
      "std_reward": 1.7877771854400635,
      "best_reward": 7.147627353668213,
      "episodes": 40,
      "steps_this_iter": 2695
    },
    {
      "iteration": 16,
      "timesteps": 46456,
      "mean_reward": 6.339115142822266,
      "max_reward": 10.58871841430664,
      "min_reward": 4.378136157989502,
      "std_reward": 1.2319241762161255,
      "best_reward": 7.147627353668213,
      "episodes": 40,
      "steps_this_iter": 2740
    },
    {
      "iteration": 17,
      "timesteps": 49977,
      "mean_reward": 6.172044277191162,
      "max_reward": 15.585400581359863,
      "min_reward": 2.387657642364502,
      "std_reward": 3.2905354499816895,
      "best_reward": 7.147627353668213,
      "episodes": 40,
      "steps_this_iter": 3521
    },
    {
      "iteration": 18,
      "timesteps": 53974,
      "mean_reward": 6.698783874511719,
      "max_reward": 25.729610443115234,
      "min_reward": 2.04032826423645,
      "std_reward": 4.48922061920166,
      "best_reward": 7.147627353668213,
      "episodes": 40,
      "steps_this_iter": 3997
    },
    {
      "iteration": 19,
      "timesteps": 57616,
      "mean_reward": 6.174532890319824,
      "max_reward": 23.534643173217773,
      "min_reward": 2.491243839263916,
      "std_reward": 3.588482618331909,
      "best_reward": 7.147627353668213,
      "episodes": 40,
      "steps_this_iter": 3642
    },
    {
      "iteration": 20,
      "timesteps": 60522,
      "mean_reward": 6.170678615570068,
      "max_reward": 9.000146865844727,
      "min_reward": 4.1035075187683105,
      "std_reward": 1.0592825412750244,
      "best_reward": 7.147627353668213,
      "episodes": 40,
      "steps_this_iter": 2906
    },
    {
      "iteration": 21,
      "timesteps": 63242,
      "mean_reward": 7.352358818054199,
      "max_reward": 20.162124633789062,
      "min_reward": 2.968177556991577,
      "std_reward": 3.669404983520508,
      "best_reward": 7.352358818054199,
      "episodes": 40,
      "steps_this_iter": 2720
    },
    {
      "iteration": 22,
      "timesteps": 66339,
      "mean_reward": 6.789703369140625,
      "max_reward": 15.009060859680176,
      "min_reward": 3.9935686588287354,
      "std_reward": 2.7844772338867188,
      "best_reward": 7.352358818054199,
      "episodes": 40,
      "steps_this_iter": 3097
    },
    {
      "iteration": 23,
      "timesteps": 69646,
      "mean_reward": 7.009863376617432,
      "max_reward": 17.678592681884766,
      "min_reward": 3.4899113178253174,
      "std_reward": 3.3667409420013428,
      "best_reward": 7.352358818054199,
      "episodes": 40,
      "steps_this_iter": 3307
    },
    {
      "iteration": 24,
      "timesteps": 72733,
      "mean_reward": 5.767881393432617,
      "max_reward": 11.714170455932617,
      "min_reward": 3.0385043621063232,
      "std_reward": 1.8391978740692139,
      "best_reward": 7.352358818054199,
      "episodes": 40,
      "steps_this_iter": 3087
    },
    {
      "iteration": 25,
      "timesteps": 76630,
      "mean_reward": 3.940420627593994,
      "max_reward": 6.160091400146484,
      "min_reward": 2.866309404373169,
      "std_reward": 0.703436017036438,
      "best_reward": 7.352358818054199,
      "episodes": 40,
      "steps_this_iter": 3897
    },
    {
      "iteration": 26,
      "timesteps": 79307,
      "mean_reward": 6.080786228179932,
      "max_reward": 13.791791915893555,
      "min_reward": 3.0300371646881104,
      "std_reward": 1.6088627576828003,
      "best_reward": 7.352358818054199,
      "episodes": 40,
      "steps_this_iter": 2677
    },
    {
      "iteration": 27,
      "timesteps": 82681,
      "mean_reward": 6.655261039733887,
      "max_reward": 18.197519302368164,
      "min_reward": 2.9671223163604736,
      "std_reward": 3.0301783084869385,
      "best_reward": 7.352358818054199,
      "episodes": 40,
      "steps_this_iter": 3374
    },
    {
      "iteration": 28,
      "timesteps": 86364,
      "mean_reward": 7.313047885894775,
      "max_reward": 21.22568702697754,
      "min_reward": 4.458226203918457,
      "std_reward": 3.016773223876953,
      "best_reward": 7.352358818054199,
      "episodes": 40,
      "steps_this_iter": 3683
    },
    {
      "iteration": 29,
      "timesteps": 89528,
      "mean_reward": 6.335205078125,
      "max_reward": 11.873263359069824,
      "min_reward": 3.554748773574829,
      "std_reward": 1.5657309293746948,
      "best_reward": 7.352358818054199,
      "episodes": 40,
      "steps_this_iter": 3164
    },
    {
      "iteration": 30,
      "timesteps": 93141,
      "mean_reward": 8.748918533325195,
      "max_reward": 17.331289291381836,
      "min_reward": 5.727541923522949,
      "std_reward": 3.2719357013702393,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3613
    },
    {
      "iteration": 31,
      "timesteps": 96499,
      "mean_reward": 7.91083288192749,
      "max_reward": 21.529964447021484,
      "min_reward": 5.349279880523682,
      "std_reward": 2.74994158744812,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3358
    },
    {
      "iteration": 32,
      "timesteps": 100040,
      "mean_reward": 6.7712202072143555,
      "max_reward": 16.28426742553711,
      "min_reward": 4.462682723999023,
      "std_reward": 2.208838701248169,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3541
    },
    {
      "iteration": 33,
      "timesteps": 103641,
      "mean_reward": 7.555447578430176,
      "max_reward": 15.056512832641602,
      "min_reward": 5.472413063049316,
      "std_reward": 1.802085041999817,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3601
    },
    {
      "iteration": 34,
      "timesteps": 107145,
      "mean_reward": 7.023813724517822,
      "max_reward": 9.89449691772461,
      "min_reward": 4.871225833892822,
      "std_reward": 1.010284185409546,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3504
    },
    {
      "iteration": 35,
      "timesteps": 109904,
      "mean_reward": 6.99371337890625,
      "max_reward": 10.347662925720215,
      "min_reward": 4.887305736541748,
      "std_reward": 1.1194144487380981,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2759
    },
    {
      "iteration": 36,
      "timesteps": 113207,
      "mean_reward": 6.784544467926025,
      "max_reward": 8.722317695617676,
      "min_reward": 5.6100053787231445,
      "std_reward": 0.7020063996315002,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3303
    },
    {
      "iteration": 37,
      "timesteps": 116786,
      "mean_reward": 7.083302974700928,
      "max_reward": 12.036750793457031,
      "min_reward": 4.255449295043945,
      "std_reward": 1.6138136386871338,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3579
    },
    {
      "iteration": 38,
      "timesteps": 120528,
      "mean_reward": 7.228163719177246,
      "max_reward": 27.80697250366211,
      "min_reward": 4.2324113845825195,
      "std_reward": 4.210698127746582,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3742
    },
    {
      "iteration": 39,
      "timesteps": 124232,
      "mean_reward": 6.111804962158203,
      "max_reward": 11.447341918945312,
      "min_reward": 2.8276610374450684,
      "std_reward": 1.8804028034210205,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3704
    },
    {
      "iteration": 40,
      "timesteps": 127693,
      "mean_reward": 6.267140865325928,
      "max_reward": 10.559334754943848,
      "min_reward": 2.1682288646698,
      "std_reward": 1.5370725393295288,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3461
    },
    {
      "iteration": 41,
      "timesteps": 131010,
      "mean_reward": 6.723518371582031,
      "max_reward": 17.72292137145996,
      "min_reward": 4.533077239990234,
      "std_reward": 2.1441562175750732,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3317
    },
    {
      "iteration": 42,
      "timesteps": 133921,
      "mean_reward": 6.2296013832092285,
      "max_reward": 11.064094543457031,
      "min_reward": 3.190474271774292,
      "std_reward": 1.4089854955673218,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2911
    },
    {
      "iteration": 43,
      "timesteps": 136721,
      "mean_reward": 6.611159324645996,
      "max_reward": 11.921866416931152,
      "min_reward": 5.272495269775391,
      "std_reward": 1.218040943145752,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2800
    },
    {
      "iteration": 44,
      "timesteps": 139905,
      "mean_reward": 6.588037967681885,
      "max_reward": 12.864997863769531,
      "min_reward": 4.694553852081299,
      "std_reward": 1.5895098447799683,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3184
    },
    {
      "iteration": 45,
      "timesteps": 143425,
      "mean_reward": 5.562468528747559,
      "max_reward": 7.992166996002197,
      "min_reward": 3.322751522064209,
      "std_reward": 1.010691523551941,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3520
    },
    {
      "iteration": 46,
      "timesteps": 146945,
      "mean_reward": 5.8717451095581055,
      "max_reward": 20.4411563873291,
      "min_reward": 3.2097439765930176,
      "std_reward": 2.5560319423675537,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3520
    },
    {
      "iteration": 47,
      "timesteps": 149873,
      "mean_reward": 7.11972188949585,
      "max_reward": 19.541704177856445,
      "min_reward": 3.8302536010742188,
      "std_reward": 2.628350257873535,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2928
    },
    {
      "iteration": 48,
      "timesteps": 152585,
      "mean_reward": 5.6724138259887695,
      "max_reward": 8.937647819519043,
      "min_reward": 3.76100492477417,
      "std_reward": 1.264337182044983,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2712
    },
    {
      "iteration": 49,
      "timesteps": 155068,
      "mean_reward": 5.85602331161499,
      "max_reward": 9.7915620803833,
      "min_reward": 3.6591339111328125,
      "std_reward": 1.0444239377975464,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2483
    },
    {
      "iteration": 50,
      "timesteps": 158173,
      "mean_reward": 6.436166286468506,
      "max_reward": 11.440459251403809,
      "min_reward": 4.873885154724121,
      "std_reward": 1.3146060705184937,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3105
    },
    {
      "iteration": 51,
      "timesteps": 161487,
      "mean_reward": 7.274560451507568,
      "max_reward": 21.98243522644043,
      "min_reward": 2.8724727630615234,
      "std_reward": 3.559328079223633,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3314
    },
    {
      "iteration": 52,
      "timesteps": 164815,
      "mean_reward": 6.55929708480835,
      "max_reward": 14.578614234924316,
      "min_reward": 3.9868075847625732,
      "std_reward": 2.139162302017212,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3328
    },
    {
      "iteration": 53,
      "timesteps": 168021,
      "mean_reward": 6.865757942199707,
      "max_reward": 16.444725036621094,
      "min_reward": 4.252923488616943,
      "std_reward": 2.122955083847046,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3206
    },
    {
      "iteration": 54,
      "timesteps": 171317,
      "mean_reward": 5.623386383056641,
      "max_reward": 8.390978813171387,
      "min_reward": 3.9417600631713867,
      "std_reward": 1.0223196744918823,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3296
    },
    {
      "iteration": 55,
      "timesteps": 174359,
      "mean_reward": 4.676902770996094,
      "max_reward": 7.065647125244141,
      "min_reward": 2.6996467113494873,
      "std_reward": 1.1201167106628418,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3042
    },
    {
      "iteration": 56,
      "timesteps": 178003,
      "mean_reward": 5.611582279205322,
      "max_reward": 11.948684692382812,
      "min_reward": 3.8909645080566406,
      "std_reward": 1.3901443481445312,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3644
    },
    {
      "iteration": 57,
      "timesteps": 181143,
      "mean_reward": 5.631943702697754,
      "max_reward": 14.41262435913086,
      "min_reward": 3.2445976734161377,
      "std_reward": 1.8469253778457642,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3140
    },
    {
      "iteration": 58,
      "timesteps": 183437,
      "mean_reward": 5.651483058929443,
      "max_reward": 8.816258430480957,
      "min_reward": 3.5519776344299316,
      "std_reward": 1.1731892824172974,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2294
    },
    {
      "iteration": 59,
      "timesteps": 186501,
      "mean_reward": 6.492867946624756,
      "max_reward": 11.946602821350098,
      "min_reward": 3.430147886276245,
      "std_reward": 1.4722484350204468,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3064
    },
    {
      "iteration": 60,
      "timesteps": 189897,
      "mean_reward": 6.337275505065918,
      "max_reward": 15.901747703552246,
      "min_reward": 3.5850119590759277,
      "std_reward": 1.9945006370544434,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3396
    },
    {
      "iteration": 61,
      "timesteps": 193029,
      "mean_reward": 5.619743347167969,
      "max_reward": 7.892208576202393,
      "min_reward": 3.9339709281921387,
      "std_reward": 0.942167341709137,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3132
    },
    {
      "iteration": 62,
      "timesteps": 194880,
      "mean_reward": 6.070489406585693,
      "max_reward": 9.1266508102417,
      "min_reward": 3.864032506942749,
      "std_reward": 0.9652645587921143,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 1851
    },
    {
      "iteration": 63,
      "timesteps": 197241,
      "mean_reward": 6.5712175369262695,
      "max_reward": 8.483773231506348,
      "min_reward": 5.461184978485107,
      "std_reward": 0.6652698516845703,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2361
    },
    {
      "iteration": 64,
      "timesteps": 199659,
      "mean_reward": 7.401561737060547,
      "max_reward": 13.35050106048584,
      "min_reward": 4.910574913024902,
      "std_reward": 1.861655831336975,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2418
    },
    {
      "iteration": 65,
      "timesteps": 203329,
      "mean_reward": 3.6294105052948,
      "max_reward": 7.149520397186279,
      "min_reward": 2.4092936515808105,
      "std_reward": 0.8555175065994263,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3670
    },
    {
      "iteration": 66,
      "timesteps": 207641,
      "mean_reward": 4.753617286682129,
      "max_reward": 13.37839126586914,
      "min_reward": 2.5303897857666016,
      "std_reward": 2.4076573848724365,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 4312
    },
    {
      "iteration": 67,
      "timesteps": 210506,
      "mean_reward": 6.119015216827393,
      "max_reward": 14.24577808380127,
      "min_reward": 3.4987666606903076,
      "std_reward": 2.349351167678833,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2865
    },
    {
      "iteration": 68,
      "timesteps": 214076,
      "mean_reward": 5.604535102844238,
      "max_reward": 14.91789436340332,
      "min_reward": 3.355175495147705,
      "std_reward": 1.9657738208770752,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3570
    },
    {
      "iteration": 69,
      "timesteps": 217363,
      "mean_reward": 4.690220355987549,
      "max_reward": 9.326264381408691,
      "min_reward": 2.5728275775909424,
      "std_reward": 1.3091984987258911,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3287
    },
    {
      "iteration": 70,
      "timesteps": 220603,
      "mean_reward": 6.528604030609131,
      "max_reward": 11.174738883972168,
      "min_reward": 2.971035957336426,
      "std_reward": 1.4716360569000244,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3240
    },
    {
      "iteration": 71,
      "timesteps": 223700,
      "mean_reward": 6.166184902191162,
      "max_reward": 9.61072826385498,
      "min_reward": 4.178261756896973,
      "std_reward": 1.1810213327407837,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3097
    },
    {
      "iteration": 72,
      "timesteps": 227196,
      "mean_reward": 6.64565372467041,
      "max_reward": 10.026204109191895,
      "min_reward": 3.994727373123169,
      "std_reward": 1.1761605739593506,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3496
    },
    {
      "iteration": 73,
      "timesteps": 230316,
      "mean_reward": 6.745905876159668,
      "max_reward": 9.441269874572754,
      "min_reward": 4.344958782196045,
      "std_reward": 0.9028679728507996,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3120
    },
    {
      "iteration": 74,
      "timesteps": 233072,
      "mean_reward": 6.876959323883057,
      "max_reward": 10.251726150512695,
      "min_reward": 5.066997051239014,
      "std_reward": 1.0032176971435547,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2756
    },
    {
      "iteration": 75,
      "timesteps": 236925,
      "mean_reward": 7.093223571777344,
      "max_reward": 18.364166259765625,
      "min_reward": 4.2750349044799805,
      "std_reward": 2.3967435359954834,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3853
    },
    {
      "iteration": 76,
      "timesteps": 240394,
      "mean_reward": 6.0472517013549805,
      "max_reward": 8.920234680175781,
      "min_reward": 3.643704414367676,
      "std_reward": 1.1579986810684204,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3469
    },
    {
      "iteration": 77,
      "timesteps": 244219,
      "mean_reward": 5.068431854248047,
      "max_reward": 9.712015151977539,
      "min_reward": 2.693514347076416,
      "std_reward": 1.414387583732605,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3825
    },
    {
      "iteration": 78,
      "timesteps": 247876,
      "mean_reward": 5.982082366943359,
      "max_reward": 12.235220909118652,
      "min_reward": 2.2539074420928955,
      "std_reward": 1.837612509727478,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3657
    },
    {
      "iteration": 79,
      "timesteps": 250873,
      "mean_reward": 6.221869468688965,
      "max_reward": 10.454423904418945,
      "min_reward": 4.530796051025391,
      "std_reward": 1.3407912254333496,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2997
    },
    {
      "iteration": 80,
      "timesteps": 254065,
      "mean_reward": 5.993218421936035,
      "max_reward": 8.899499893188477,
      "min_reward": 2.842172861099243,
      "std_reward": 1.437443733215332,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3192
    },
    {
      "iteration": 81,
      "timesteps": 257504,
      "mean_reward": 5.898490905761719,
      "max_reward": 11.613104820251465,
      "min_reward": 2.513756513595581,
      "std_reward": 2.033851146697998,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3439
    },
    {
      "iteration": 82,
      "timesteps": 261942,
      "mean_reward": 7.115910530090332,
      "max_reward": 9.85789680480957,
      "min_reward": 5.149680137634277,
      "std_reward": 1.1617008447647095,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 4438
    },
    {
      "iteration": 83,
      "timesteps": 265363,
      "mean_reward": 6.7019500732421875,
      "max_reward": 11.05782699584961,
      "min_reward": 4.6390461921691895,
      "std_reward": 1.3721592426300049,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3421
    },
    {
      "iteration": 84,
      "timesteps": 268399,
      "mean_reward": 7.158100128173828,
      "max_reward": 13.37717342376709,
      "min_reward": 4.503749370574951,
      "std_reward": 1.62620210647583,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3036
    },
    {
      "iteration": 85,
      "timesteps": 272001,
      "mean_reward": 7.463971138000488,
      "max_reward": 11.397231101989746,
      "min_reward": 3.6822736263275146,
      "std_reward": 1.5538347959518433,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3602
    },
    {
      "iteration": 86,
      "timesteps": 275041,
      "mean_reward": 7.203777313232422,
      "max_reward": 10.811347961425781,
      "min_reward": 5.221367835998535,
      "std_reward": 1.2655450105667114,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3040
    },
    {
      "iteration": 87,
      "timesteps": 278049,
      "mean_reward": 7.337084770202637,
      "max_reward": 16.790332794189453,
      "min_reward": 4.519744396209717,
      "std_reward": 2.2680468559265137,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3008
    },
    {
      "iteration": 88,
      "timesteps": 281261,
      "mean_reward": 7.17691707611084,
      "max_reward": 11.930438041687012,
      "min_reward": 3.648707389831543,
      "std_reward": 1.5506623983383179,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3212
    },
    {
      "iteration": 89,
      "timesteps": 285339,
      "mean_reward": 6.824671745300293,
      "max_reward": 9.859997749328613,
      "min_reward": 3.6030080318450928,
      "std_reward": 1.4967365264892578,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 4078
    },
    {
      "iteration": 90,
      "timesteps": 289219,
      "mean_reward": 7.1844024658203125,
      "max_reward": 14.553690910339355,
      "min_reward": 4.969720363616943,
      "std_reward": 1.8188225030899048,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3880
    },
    {
      "iteration": 91,
      "timesteps": 292516,
      "mean_reward": 6.9138946533203125,
      "max_reward": 9.44897174835205,
      "min_reward": 4.4091105461120605,
      "std_reward": 1.4243494272232056,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3297
    },
    {
      "iteration": 92,
      "timesteps": 295916,
      "mean_reward": 7.824601650238037,
      "max_reward": 10.568568229675293,
      "min_reward": 5.100663661956787,
      "std_reward": 1.2296545505523682,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3400
    },
    {
      "iteration": 93,
      "timesteps": 299668,
      "mean_reward": 6.927703857421875,
      "max_reward": 11.431652069091797,
      "min_reward": 4.292008399963379,
      "std_reward": 1.5480329990386963,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3752
    },
    {
      "iteration": 94,
      "timesteps": 302635,
      "mean_reward": 7.088274955749512,
      "max_reward": 11.611593246459961,
      "min_reward": 2.962096929550171,
      "std_reward": 1.773673176765442,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2967
    },
    {
      "iteration": 95,
      "timesteps": 306459,
      "mean_reward": 7.138467311859131,
      "max_reward": 12.456376075744629,
      "min_reward": 4.59903621673584,
      "std_reward": 1.6133472919464111,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3824
    },
    {
      "iteration": 96,
      "timesteps": 309581,
      "mean_reward": 7.3407769203186035,
      "max_reward": 10.432242393493652,
      "min_reward": 5.3741583824157715,
      "std_reward": 1.2326699495315552,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3122
    },
    {
      "iteration": 97,
      "timesteps": 313060,
      "mean_reward": 6.956925868988037,
      "max_reward": 10.70283031463623,
      "min_reward": 3.4273593425750732,
      "std_reward": 1.596958875656128,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3479
    },
    {
      "iteration": 98,
      "timesteps": 316395,
      "mean_reward": 7.395338535308838,
      "max_reward": 22.63533592224121,
      "min_reward": 4.390603542327881,
      "std_reward": 2.747062921524048,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3335
    },
    {
      "iteration": 99,
      "timesteps": 319757,
      "mean_reward": 6.998477935791016,
      "max_reward": 9.207259178161621,
      "min_reward": 4.745162010192871,
      "std_reward": 1.1686114072799683,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3362
    },
    {
      "iteration": 100,
      "timesteps": 323332,
      "mean_reward": 7.119997501373291,
      "max_reward": 13.402517318725586,
      "min_reward": 4.345727443695068,
      "std_reward": 1.5155953168869019,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3575
    },
    {
      "iteration": 101,
      "timesteps": 326448,
      "mean_reward": 6.980788230895996,
      "max_reward": 8.703145980834961,
      "min_reward": 4.307239055633545,
      "std_reward": 1.0175930261611938,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3116
    },
    {
      "iteration": 102,
      "timesteps": 329755,
      "mean_reward": 6.4495649337768555,
      "max_reward": 8.346002578735352,
      "min_reward": 4.649662017822266,
      "std_reward": 0.9142446517944336,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3307
    },
    {
      "iteration": 103,
      "timesteps": 333066,
      "mean_reward": 6.593823432922363,
      "max_reward": 8.739494323730469,
      "min_reward": 4.813343524932861,
      "std_reward": 0.9869263768196106,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3311
    },
    {
      "iteration": 104,
      "timesteps": 336282,
      "mean_reward": 7.470412254333496,
      "max_reward": 11.942429542541504,
      "min_reward": 5.049241542816162,
      "std_reward": 1.649182677268982,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3216
    },
    {
      "iteration": 105,
      "timesteps": 339626,
      "mean_reward": 7.924995422363281,
      "max_reward": 18.027509689331055,
      "min_reward": 5.320860385894775,
      "std_reward": 2.067948341369629,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3344
    },
    {
      "iteration": 106,
      "timesteps": 342471,
      "mean_reward": 6.641761779785156,
      "max_reward": 10.977566719055176,
      "min_reward": 4.410264015197754,
      "std_reward": 1.4158251285552979,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2845
    },
    {
      "iteration": 107,
      "timesteps": 345953,
      "mean_reward": 7.390267848968506,
      "max_reward": 10.260712623596191,
      "min_reward": 5.185116767883301,
      "std_reward": 1.1961191892623901,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3482
    },
    {
      "iteration": 108,
      "timesteps": 349279,
      "mean_reward": 6.413764953613281,
      "max_reward": 14.937630653381348,
      "min_reward": 3.6943602561950684,
      "std_reward": 2.167330265045166,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3326
    },
    {
      "iteration": 109,
      "timesteps": 352365,
      "mean_reward": 6.331793785095215,
      "max_reward": 10.970622062683105,
      "min_reward": 3.162262201309204,
      "std_reward": 1.54750394821167,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3086
    },
    {
      "iteration": 110,
      "timesteps": 355537,
      "mean_reward": 6.583003997802734,
      "max_reward": 12.013909339904785,
      "min_reward": 3.7129762172698975,
      "std_reward": 1.7505775690078735,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3172
    },
    {
      "iteration": 111,
      "timesteps": 357997,
      "mean_reward": 5.619006156921387,
      "max_reward": 7.883121967315674,
      "min_reward": 3.5107476711273193,
      "std_reward": 1.2675944566726685,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2460
    },
    {
      "iteration": 112,
      "timesteps": 360860,
      "mean_reward": 6.53375244140625,
      "max_reward": 12.963173866271973,
      "min_reward": 3.982558012008667,
      "std_reward": 1.5288423299789429,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2863
    },
    {
      "iteration": 113,
      "timesteps": 363816,
      "mean_reward": 6.835590362548828,
      "max_reward": 14.34959888458252,
      "min_reward": 4.904685020446777,
      "std_reward": 1.5980488061904907,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2956
    },
    {
      "iteration": 114,
      "timesteps": 366534,
      "mean_reward": 5.89895486831665,
      "max_reward": 17.88878059387207,
      "min_reward": 2.815861463546753,
      "std_reward": 2.208484411239624,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2718
    },
    {
      "iteration": 115,
      "timesteps": 369465,
      "mean_reward": 6.4948320388793945,
      "max_reward": 11.389603614807129,
      "min_reward": 3.4257240295410156,
      "std_reward": 1.7290668487548828,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2931
    },
    {
      "iteration": 116,
      "timesteps": 372263,
      "mean_reward": 6.003874778747559,
      "max_reward": 10.154315948486328,
      "min_reward": 3.3263978958129883,
      "std_reward": 1.2719180583953857,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2798
    },
    {
      "iteration": 117,
      "timesteps": 374886,
      "mean_reward": 5.53046178817749,
      "max_reward": 10.221692085266113,
      "min_reward": 3.1214120388031006,
      "std_reward": 1.2760313749313354,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2623
    },
    {
      "iteration": 118,
      "timesteps": 377595,
      "mean_reward": 6.633338928222656,
      "max_reward": 9.66018295288086,
      "min_reward": 4.102712154388428,
      "std_reward": 1.0726131200790405,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2709
    },
    {
      "iteration": 119,
      "timesteps": 380302,
      "mean_reward": 6.476649284362793,
      "max_reward": 8.977174758911133,
      "min_reward": 4.745908737182617,
      "std_reward": 0.9064326286315918,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2707
    },
    {
      "iteration": 120,
      "timesteps": 383689,
      "mean_reward": 7.027533531188965,
      "max_reward": 9.005290985107422,
      "min_reward": 4.7822980880737305,
      "std_reward": 0.9929377436637878,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3387
    },
    {
      "iteration": 121,
      "timesteps": 386563,
      "mean_reward": 6.1615095138549805,
      "max_reward": 8.924235343933105,
      "min_reward": 3.61842942237854,
      "std_reward": 1.1881409883499146,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2874
    },
    {
      "iteration": 122,
      "timesteps": 388945,
      "mean_reward": 6.678814888000488,
      "max_reward": 11.17885684967041,
      "min_reward": 4.890198707580566,
      "std_reward": 1.0671435594558716,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2382
    },
    {
      "iteration": 123,
      "timesteps": 391849,
      "mean_reward": 6.869580268859863,
      "max_reward": 11.15422534942627,
      "min_reward": 5.245190143585205,
      "std_reward": 1.1513493061065674,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2904
    },
    {
      "iteration": 124,
      "timesteps": 394773,
      "mean_reward": 6.116612911224365,
      "max_reward": 8.28547191619873,
      "min_reward": 3.441969633102417,
      "std_reward": 1.0005459785461426,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2924
    },
    {
      "iteration": 125,
      "timesteps": 397951,
      "mean_reward": 6.867941379547119,
      "max_reward": 9.180469512939453,
      "min_reward": 4.188239097595215,
      "std_reward": 0.9497137665748596,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3178
    },
    {
      "iteration": 126,
      "timesteps": 401460,
      "mean_reward": 6.896009922027588,
      "max_reward": 10.660419464111328,
      "min_reward": 4.840977191925049,
      "std_reward": 1.1635385751724243,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3509
    },
    {
      "iteration": 127,
      "timesteps": 404216,
      "mean_reward": 6.623953819274902,
      "max_reward": 9.309082984924316,
      "min_reward": 4.99243688583374,
      "std_reward": 0.9647313952445984,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2756
    },
    {
      "iteration": 128,
      "timesteps": 407368,
      "mean_reward": 6.696194648742676,
      "max_reward": 18.888246536254883,
      "min_reward": 3.427952766418457,
      "std_reward": 2.3549137115478516,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3152
    },
    {
      "iteration": 129,
      "timesteps": 410606,
      "mean_reward": 6.801730155944824,
      "max_reward": 11.13436508178711,
      "min_reward": 5.068729877471924,
      "std_reward": 1.2253544330596924,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3238
    },
    {
      "iteration": 130,
      "timesteps": 413111,
      "mean_reward": 6.717530727386475,
      "max_reward": 8.644153594970703,
      "min_reward": 4.4241719245910645,
      "std_reward": 0.9644967317581177,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2505
    },
    {
      "iteration": 131,
      "timesteps": 416182,
      "mean_reward": 6.912938117980957,
      "max_reward": 12.674973487854004,
      "min_reward": 4.672398567199707,
      "std_reward": 1.3309900760650635,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3071
    },
    {
      "iteration": 132,
      "timesteps": 418741,
      "mean_reward": 6.337240695953369,
      "max_reward": 9.55952262878418,
      "min_reward": 4.480313301086426,
      "std_reward": 1.0335633754730225,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2559
    },
    {
      "iteration": 133,
      "timesteps": 422114,
      "mean_reward": 6.968560695648193,
      "max_reward": 10.092843055725098,
      "min_reward": 3.550875663757324,
      "std_reward": 1.6107677221298218,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3373
    },
    {
      "iteration": 134,
      "timesteps": 425126,
      "mean_reward": 6.426258087158203,
      "max_reward": 8.410893440246582,
      "min_reward": 2.724684476852417,
      "std_reward": 1.3358986377716064,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3012
    },
    {
      "iteration": 135,
      "timesteps": 428030,
      "mean_reward": 7.109027862548828,
      "max_reward": 9.353129386901855,
      "min_reward": 3.280174970626831,
      "std_reward": 1.2892866134643555,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2904
    },
    {
      "iteration": 136,
      "timesteps": 431016,
      "mean_reward": 7.087994575500488,
      "max_reward": 10.284829139709473,
      "min_reward": 4.952767848968506,
      "std_reward": 1.3666990995407104,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2986
    },
    {
      "iteration": 137,
      "timesteps": 434069,
      "mean_reward": 6.615642547607422,
      "max_reward": 21.76629638671875,
      "min_reward": 3.071359157562256,
      "std_reward": 3.10585618019104,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3053
    },
    {
      "iteration": 138,
      "timesteps": 436804,
      "mean_reward": 6.897398471832275,
      "max_reward": 9.522911071777344,
      "min_reward": 4.462489604949951,
      "std_reward": 1.1399526596069336,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2735
    },
    {
      "iteration": 139,
      "timesteps": 439573,
      "mean_reward": 5.84585428237915,
      "max_reward": 13.905887603759766,
      "min_reward": 2.7514052391052246,
      "std_reward": 2.0510551929473877,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2769
    },
    {
      "iteration": 140,
      "timesteps": 442625,
      "mean_reward": 6.5178070068359375,
      "max_reward": 10.089559555053711,
      "min_reward": 4.439127445220947,
      "std_reward": 1.2849535942077637,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3052
    },
    {
      "iteration": 141,
      "timesteps": 445500,
      "mean_reward": 6.434435844421387,
      "max_reward": 8.806045532226562,
      "min_reward": 3.792912006378174,
      "std_reward": 0.9923328161239624,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2875
    },
    {
      "iteration": 142,
      "timesteps": 448356,
      "mean_reward": 7.2973761558532715,
      "max_reward": 13.824580192565918,
      "min_reward": 3.8847312927246094,
      "std_reward": 1.8530867099761963,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2856
    },
    {
      "iteration": 143,
      "timesteps": 451564,
      "mean_reward": 5.7992777824401855,
      "max_reward": 9.741377830505371,
      "min_reward": 2.4803848266601562,
      "std_reward": 1.6900805234909058,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3208
    },
    {
      "iteration": 144,
      "timesteps": 454770,
      "mean_reward": 6.7167205810546875,
      "max_reward": 19.557523727416992,
      "min_reward": 4.092988967895508,
      "std_reward": 2.595292329788208,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3206
    },
    {
      "iteration": 145,
      "timesteps": 458048,
      "mean_reward": 6.3715362548828125,
      "max_reward": 11.649904251098633,
      "min_reward": 4.334760665893555,
      "std_reward": 1.4062055349349976,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3278
    },
    {
      "iteration": 146,
      "timesteps": 461682,
      "mean_reward": 5.788507461547852,
      "max_reward": 16.124942779541016,
      "min_reward": 2.925387382507324,
      "std_reward": 2.5911707878112793,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3634
    },
    {
      "iteration": 147,
      "timesteps": 464592,
      "mean_reward": 6.315225124359131,
      "max_reward": 15.578747749328613,
      "min_reward": 3.0397555828094482,
      "std_reward": 1.9088813066482544,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2910
    },
    {
      "iteration": 148,
      "timesteps": 467879,
      "mean_reward": 5.610201358795166,
      "max_reward": 9.045117378234863,
      "min_reward": 3.1230642795562744,
      "std_reward": 1.3795042037963867,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3287
    },
    {
      "iteration": 149,
      "timesteps": 470512,
      "mean_reward": 6.484705924987793,
      "max_reward": 12.041326522827148,
      "min_reward": 3.524698495864868,
      "std_reward": 1.3343952894210815,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2633
    },
    {
      "iteration": 150,
      "timesteps": 473342,
      "mean_reward": 6.463074684143066,
      "max_reward": 9.603983879089355,
      "min_reward": 4.174675464630127,
      "std_reward": 1.0080827474594116,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2830
    },
    {
      "iteration": 151,
      "timesteps": 476479,
      "mean_reward": 7.105900764465332,
      "max_reward": 20.827959060668945,
      "min_reward": 4.455356597900391,
      "std_reward": 2.860483407974243,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3137
    },
    {
      "iteration": 152,
      "timesteps": 479731,
      "mean_reward": 6.900042533874512,
      "max_reward": 24.818466186523438,
      "min_reward": 4.543666362762451,
      "std_reward": 3.050626277923584,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3252
    },
    {
      "iteration": 153,
      "timesteps": 482330,
      "mean_reward": 5.994722843170166,
      "max_reward": 9.244629859924316,
      "min_reward": 3.059802770614624,
      "std_reward": 1.2239164113998413,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2599
    },
    {
      "iteration": 154,
      "timesteps": 486212,
      "mean_reward": 5.211480140686035,
      "max_reward": 8.112972259521484,
      "min_reward": 2.481306314468384,
      "std_reward": 1.499218463897705,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3882
    },
    {
      "iteration": 155,
      "timesteps": 489549,
      "mean_reward": 6.2159576416015625,
      "max_reward": 15.073870658874512,
      "min_reward": 2.047586679458618,
      "std_reward": 2.2819740772247314,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3337
    },
    {
      "iteration": 156,
      "timesteps": 492992,
      "mean_reward": 6.624449729919434,
      "max_reward": 21.953401565551758,
      "min_reward": 3.088893413543701,
      "std_reward": 3.219848394393921,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3443
    },
    {
      "iteration": 157,
      "timesteps": 496582,
      "mean_reward": 6.1541948318481445,
      "max_reward": 18.06328773498535,
      "min_reward": 1.6686019897460938,
      "std_reward": 2.9139621257781982,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3590
    },
    {
      "iteration": 158,
      "timesteps": 500125,
      "mean_reward": 6.602308750152588,
      "max_reward": 11.365071296691895,
      "min_reward": 3.853128433227539,
      "std_reward": 1.4591351747512817,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3543
    },
    {
      "iteration": 159,
      "timesteps": 504212,
      "mean_reward": 7.484849452972412,
      "max_reward": 23.335575103759766,
      "min_reward": 4.126782417297363,
      "std_reward": 3.479987859725952,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 4087
    },
    {
      "iteration": 160,
      "timesteps": 508207,
      "mean_reward": 5.757533073425293,
      "max_reward": 8.851936340332031,
      "min_reward": 3.0189297199249268,
      "std_reward": 1.155864953994751,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3995
    },
    {
      "iteration": 161,
      "timesteps": 511170,
      "mean_reward": 6.153292179107666,
      "max_reward": 9.317980766296387,
      "min_reward": 3.750002384185791,
      "std_reward": 1.296270728111267,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2963
    },
    {
      "iteration": 162,
      "timesteps": 514424,
      "mean_reward": 6.19071626663208,
      "max_reward": 12.739142417907715,
      "min_reward": 3.1371967792510986,
      "std_reward": 1.7761374711990356,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3254
    },
    {
      "iteration": 163,
      "timesteps": 517907,
      "mean_reward": 5.913107872009277,
      "max_reward": 14.554794311523438,
      "min_reward": 2.8084893226623535,
      "std_reward": 2.1355926990509033,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3483
    },
    {
      "iteration": 164,
      "timesteps": 521228,
      "mean_reward": 6.708123683929443,
      "max_reward": 15.234103202819824,
      "min_reward": 5.137851238250732,
      "std_reward": 1.9371414184570312,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3321
    },
    {
      "iteration": 165,
      "timesteps": 525379,
      "mean_reward": 6.338574409484863,
      "max_reward": 25.235069274902344,
      "min_reward": 3.6224725246429443,
      "std_reward": 3.6121513843536377,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 4151
    },
    {
      "iteration": 166,
      "timesteps": 529144,
      "mean_reward": 5.372768402099609,
      "max_reward": 10.240995407104492,
      "min_reward": 2.929560899734497,
      "std_reward": 1.743452548980713,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3765
    },
    {
      "iteration": 167,
      "timesteps": 532537,
      "mean_reward": 5.400168418884277,
      "max_reward": 9.620017051696777,
      "min_reward": 2.6228480339050293,
      "std_reward": 1.3932201862335205,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3393
    },
    {
      "iteration": 168,
      "timesteps": 535844,
      "mean_reward": 6.0015764236450195,
      "max_reward": 9.899115562438965,
      "min_reward": 2.9397623538970947,
      "std_reward": 1.520060420036316,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3307
    },
    {
      "iteration": 169,
      "timesteps": 539544,
      "mean_reward": 5.223396301269531,
      "max_reward": 9.511996269226074,
      "min_reward": 3.131208658218384,
      "std_reward": 1.3468838930130005,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3700
    },
    {
      "iteration": 170,
      "timesteps": 543264,
      "mean_reward": 5.981092929840088,
      "max_reward": 10.855273246765137,
      "min_reward": 4.145601749420166,
      "std_reward": 1.443510890007019,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3720
    },
    {
      "iteration": 171,
      "timesteps": 547509,
      "mean_reward": 5.866060733795166,
      "max_reward": 11.318916320800781,
      "min_reward": 3.0878384113311768,
      "std_reward": 1.6446807384490967,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 4245
    },
    {
      "iteration": 172,
      "timesteps": 550770,
      "mean_reward": 6.084665775299072,
      "max_reward": 11.4826021194458,
      "min_reward": 3.133780002593994,
      "std_reward": 1.6818832159042358,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3261
    },
    {
      "iteration": 173,
      "timesteps": 554260,
      "mean_reward": 5.907926559448242,
      "max_reward": 9.232999801635742,
      "min_reward": 3.8870105743408203,
      "std_reward": 1.0603443384170532,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3490
    },
    {
      "iteration": 174,
      "timesteps": 557454,
      "mean_reward": 4.90000581741333,
      "max_reward": 8.323213577270508,
      "min_reward": 2.2396202087402344,
      "std_reward": 1.5931733846664429,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3194
    },
    {
      "iteration": 175,
      "timesteps": 561406,
      "mean_reward": 5.277019500732422,
      "max_reward": 10.179203987121582,
      "min_reward": 2.2573134899139404,
      "std_reward": 1.6799726486206055,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3952
    },
    {
      "iteration": 176,
      "timesteps": 564940,
      "mean_reward": 4.930233001708984,
      "max_reward": 12.163615226745605,
      "min_reward": 2.0282115936279297,
      "std_reward": 1.9494712352752686,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3534
    },
    {
      "iteration": 177,
      "timesteps": 568322,
      "mean_reward": 5.350087642669678,
      "max_reward": 9.70719051361084,
      "min_reward": 1.6593749523162842,
      "std_reward": 1.6153696775436401,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3382
    },
    {
      "iteration": 178,
      "timesteps": 571521,
      "mean_reward": 6.333383560180664,
      "max_reward": 12.367426872253418,
      "min_reward": 3.519706964492798,
      "std_reward": 1.9974898099899292,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3199
    },
    {
      "iteration": 179,
      "timesteps": 574824,
      "mean_reward": 5.065879821777344,
      "max_reward": 8.568218231201172,
      "min_reward": 1.5938628911972046,
      "std_reward": 1.9897435903549194,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3303
    },
    {
      "iteration": 180,
      "timesteps": 578518,
      "mean_reward": 5.016938209533691,
      "max_reward": 9.593143463134766,
      "min_reward": 2.3881051540374756,
      "std_reward": 1.4486474990844727,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3694
    },
    {
      "iteration": 181,
      "timesteps": 581907,
      "mean_reward": 5.189116477966309,
      "max_reward": 13.98663330078125,
      "min_reward": 1.9179110527038574,
      "std_reward": 2.251277446746826,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3389
    },
    {
      "iteration": 182,
      "timesteps": 585330,
      "mean_reward": 5.457083225250244,
      "max_reward": 15.965384483337402,
      "min_reward": 2.299523115158081,
      "std_reward": 2.324828624725342,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3423
    },
    {
      "iteration": 183,
      "timesteps": 588638,
      "mean_reward": 5.905646324157715,
      "max_reward": 20.12115478515625,
      "min_reward": 2.707632303237915,
      "std_reward": 2.7607505321502686,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3308
    },
    {
      "iteration": 184,
      "timesteps": 592274,
      "mean_reward": 5.949492454528809,
      "max_reward": 16.48164176940918,
      "min_reward": 2.2966415882110596,
      "std_reward": 2.823920726776123,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3636
    },
    {
      "iteration": 185,
      "timesteps": 594990,
      "mean_reward": 6.067402362823486,
      "max_reward": 9.660980224609375,
      "min_reward": 3.9690582752227783,
      "std_reward": 1.069228172302246,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2716
    },
    {
      "iteration": 186,
      "timesteps": 598936,
      "mean_reward": 5.877928733825684,
      "max_reward": 16.765073776245117,
      "min_reward": 2.14220929145813,
      "std_reward": 2.323991298675537,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3946
    },
    {
      "iteration": 187,
      "timesteps": 602441,
      "mean_reward": 6.037888526916504,
      "max_reward": 14.853428840637207,
      "min_reward": 2.730560302734375,
      "std_reward": 2.0343873500823975,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3505
    },
    {
      "iteration": 188,
      "timesteps": 605768,
      "mean_reward": 6.59042501449585,
      "max_reward": 11.373998641967773,
      "min_reward": 2.5350019931793213,
      "std_reward": 1.6251760721206665,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3327
    },
    {
      "iteration": 189,
      "timesteps": 608693,
      "mean_reward": 6.290685176849365,
      "max_reward": 10.468215942382812,
      "min_reward": 4.102013111114502,
      "std_reward": 1.0912588834762573,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2925
    },
    {
      "iteration": 190,
      "timesteps": 611746,
      "mean_reward": 5.972853660583496,
      "max_reward": 12.876178741455078,
      "min_reward": 3.588204860687256,
      "std_reward": 1.8644300699234009,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3053
    },
    {
      "iteration": 191,
      "timesteps": 614452,
      "mean_reward": 5.897295951843262,
      "max_reward": 11.794775009155273,
      "min_reward": 3.6382429599761963,
      "std_reward": 1.2719707489013672,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2706
    },
    {
      "iteration": 192,
      "timesteps": 617494,
      "mean_reward": 4.248835563659668,
      "max_reward": 13.674440383911133,
      "min_reward": 1.5913165807724,
      "std_reward": 2.085537910461426,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3042
    },
    {
      "iteration": 193,
      "timesteps": 620592,
      "mean_reward": 5.7186079025268555,
      "max_reward": 12.986577033996582,
      "min_reward": 1.9888983964920044,
      "std_reward": 2.329704523086548,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3098
    },
    {
      "iteration": 194,
      "timesteps": 623669,
      "mean_reward": 6.592852592468262,
      "max_reward": 8.477389335632324,
      "min_reward": 4.0476789474487305,
      "std_reward": 0.983857274055481,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3077
    },
    {
      "iteration": 195,
      "timesteps": 626482,
      "mean_reward": 6.013492107391357,
      "max_reward": 11.489219665527344,
      "min_reward": 3.037492513656616,
      "std_reward": 1.4940664768218994,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2813
    },
    {
      "iteration": 196,
      "timesteps": 629396,
      "mean_reward": 6.115554332733154,
      "max_reward": 14.389859199523926,
      "min_reward": 3.475922107696533,
      "std_reward": 1.926274299621582,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2914
    },
    {
      "iteration": 197,
      "timesteps": 632686,
      "mean_reward": 5.428371906280518,
      "max_reward": 9.653438568115234,
      "min_reward": 2.0261340141296387,
      "std_reward": 1.537125587463379,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3290
    },
    {
      "iteration": 198,
      "timesteps": 636313,
      "mean_reward": 6.12713623046875,
      "max_reward": 8.994335174560547,
      "min_reward": 3.4187893867492676,
      "std_reward": 1.1584135293960571,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3627
    },
    {
      "iteration": 199,
      "timesteps": 639532,
      "mean_reward": 5.600870609283447,
      "max_reward": 9.700032234191895,
      "min_reward": 1.7028404474258423,
      "std_reward": 2.034130573272705,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3219
    },
    {
      "iteration": 200,
      "timesteps": 642298,
      "mean_reward": 7.349621772766113,
      "max_reward": 12.287487983703613,
      "min_reward": 2.2182223796844482,
      "std_reward": 1.9123868942260742,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2766
    },
    {
      "iteration": 201,
      "timesteps": 645437,
      "mean_reward": 6.488044738769531,
      "max_reward": 8.88247299194336,
      "min_reward": 3.2618792057037354,
      "std_reward": 1.3111180067062378,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3139
    },
    {
      "iteration": 202,
      "timesteps": 647970,
      "mean_reward": 6.9715576171875,
      "max_reward": 11.007247924804688,
      "min_reward": 4.2973408699035645,
      "std_reward": 1.508239507675171,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2533
    },
    {
      "iteration": 203,
      "timesteps": 651089,
      "mean_reward": 6.230007648468018,
      "max_reward": 9.735993385314941,
      "min_reward": 3.326840400695801,
      "std_reward": 1.2254904508590698,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3119
    },
    {
      "iteration": 204,
      "timesteps": 653655,
      "mean_reward": 7.275261878967285,
      "max_reward": 11.478800773620605,
      "min_reward": 3.9996871948242188,
      "std_reward": 1.5716084241867065,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2566
    },
    {
      "iteration": 205,
      "timesteps": 656644,
      "mean_reward": 6.200497627258301,
      "max_reward": 11.226875305175781,
      "min_reward": 2.75689959526062,
      "std_reward": 1.9521749019622803,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2989
    },
    {
      "iteration": 206,
      "timesteps": 659094,
      "mean_reward": 7.318717002868652,
      "max_reward": 9.285028457641602,
      "min_reward": 5.026468753814697,
      "std_reward": 1.0249437093734741,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2450
    },
    {
      "iteration": 207,
      "timesteps": 661626,
      "mean_reward": 6.211939334869385,
      "max_reward": 8.480113983154297,
      "min_reward": 3.1194515228271484,
      "std_reward": 1.366836428642273,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2532
    },
    {
      "iteration": 208,
      "timesteps": 664465,
      "mean_reward": 5.890833854675293,
      "max_reward": 10.344611167907715,
      "min_reward": 2.317251205444336,
      "std_reward": 1.8360580205917358,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2839
    },
    {
      "iteration": 209,
      "timesteps": 666689,
      "mean_reward": 7.064040184020996,
      "max_reward": 9.125370025634766,
      "min_reward": 3.277634620666504,
      "std_reward": 1.1014946699142456,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2224
    },
    {
      "iteration": 210,
      "timesteps": 668950,
      "mean_reward": 7.290936470031738,
      "max_reward": 16.611129760742188,
      "min_reward": 3.618929386138916,
      "std_reward": 1.8022112846374512,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2261
    },
    {
      "iteration": 211,
      "timesteps": 671666,
      "mean_reward": 6.715641975402832,
      "max_reward": 9.06202220916748,
      "min_reward": 3.9326529502868652,
      "std_reward": 1.1106051206588745,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2716
    },
    {
      "iteration": 212,
      "timesteps": 674188,
      "mean_reward": 7.047358512878418,
      "max_reward": 9.447604179382324,
      "min_reward": 3.0463268756866455,
      "std_reward": 1.1873712539672852,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2522
    },
    {
      "iteration": 213,
      "timesteps": 676358,
      "mean_reward": 7.071883201599121,
      "max_reward": 9.196352005004883,
      "min_reward": 4.5350751876831055,
      "std_reward": 1.062563419342041,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2170
    },
    {
      "iteration": 214,
      "timesteps": 679331,
      "mean_reward": 5.735254764556885,
      "max_reward": 11.192941665649414,
      "min_reward": 3.1163461208343506,
      "std_reward": 1.1576106548309326,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2973
    },
    {
      "iteration": 215,
      "timesteps": 682601,
      "mean_reward": 4.968588829040527,
      "max_reward": 8.245087623596191,
      "min_reward": 1.9127287864685059,
      "std_reward": 1.5499080419540405,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3270
    },
    {
      "iteration": 216,
      "timesteps": 685565,
      "mean_reward": 5.582329750061035,
      "max_reward": 12.966245651245117,
      "min_reward": 2.1329314708709717,
      "std_reward": 1.8423198461532593,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2964
    },
    {
      "iteration": 217,
      "timesteps": 688472,
      "mean_reward": 6.205708026885986,
      "max_reward": 9.415701866149902,
      "min_reward": 2.6781439781188965,
      "std_reward": 1.412876844406128,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2907
    },
    {
      "iteration": 218,
      "timesteps": 691774,
      "mean_reward": 6.2008056640625,
      "max_reward": 9.566500663757324,
      "min_reward": 2.1890528202056885,
      "std_reward": 1.6046503782272339,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3302
    },
    {
      "iteration": 219,
      "timesteps": 694274,
      "mean_reward": 7.088456630706787,
      "max_reward": 10.72425651550293,
      "min_reward": 4.139378547668457,
      "std_reward": 1.4214586019515991,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2500
    },
    {
      "iteration": 220,
      "timesteps": 696894,
      "mean_reward": 5.763989448547363,
      "max_reward": 7.923848628997803,
      "min_reward": 2.3772172927856445,
      "std_reward": 1.1534690856933594,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2620
    },
    {
      "iteration": 221,
      "timesteps": 699270,
      "mean_reward": 6.685341835021973,
      "max_reward": 10.729026794433594,
      "min_reward": 3.5811028480529785,
      "std_reward": 1.3475966453552246,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2376
    },
    {
      "iteration": 222,
      "timesteps": 702130,
      "mean_reward": 5.230374813079834,
      "max_reward": 8.404994010925293,
      "min_reward": 2.008629560470581,
      "std_reward": 1.9809685945510864,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2860
    },
    {
      "iteration": 223,
      "timesteps": 704648,
      "mean_reward": 6.926648139953613,
      "max_reward": 9.258150100708008,
      "min_reward": 4.025191783905029,
      "std_reward": 1.3120299577713013,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2518
    },
    {
      "iteration": 224,
      "timesteps": 707450,
      "mean_reward": 6.858731269836426,
      "max_reward": 9.160489082336426,
      "min_reward": 2.782599687576294,
      "std_reward": 1.6344913244247437,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2802
    },
    {
      "iteration": 225,
      "timesteps": 710033,
      "mean_reward": 7.064864158630371,
      "max_reward": 9.904973983764648,
      "min_reward": 3.7670295238494873,
      "std_reward": 1.46100652217865,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2583
    },
    {
      "iteration": 226,
      "timesteps": 712661,
      "mean_reward": 7.703282833099365,
      "max_reward": 19.691463470458984,
      "min_reward": 4.884479522705078,
      "std_reward": 2.099139451980591,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2628
    },
    {
      "iteration": 227,
      "timesteps": 715091,
      "mean_reward": 6.888828277587891,
      "max_reward": 10.806632995605469,
      "min_reward": 2.969275951385498,
      "std_reward": 1.7400867938995361,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2430
    },
    {
      "iteration": 228,
      "timesteps": 717359,
      "mean_reward": 6.887629508972168,
      "max_reward": 8.836631774902344,
      "min_reward": 5.177309513092041,
      "std_reward": 0.9416985511779785,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2268
    },
    {
      "iteration": 229,
      "timesteps": 719907,
      "mean_reward": 6.944226264953613,
      "max_reward": 9.106941223144531,
      "min_reward": 3.098750591278076,
      "std_reward": 1.2423226833343506,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2548
    },
    {
      "iteration": 230,
      "timesteps": 722448,
      "mean_reward": 6.670742034912109,
      "max_reward": 8.612492561340332,
      "min_reward": 4.67144250869751,
      "std_reward": 0.8980762362480164,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2541
    },
    {
      "iteration": 231,
      "timesteps": 724679,
      "mean_reward": 6.072037220001221,
      "max_reward": 8.27584457397461,
      "min_reward": 3.3164427280426025,
      "std_reward": 1.2390562295913696,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2231
    },
    {
      "iteration": 232,
      "timesteps": 726800,
      "mean_reward": 7.040971279144287,
      "max_reward": 9.067818641662598,
      "min_reward": 5.254582405090332,
      "std_reward": 0.8949429392814636,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2121
    },
    {
      "iteration": 233,
      "timesteps": 729248,
      "mean_reward": 6.100183963775635,
      "max_reward": 8.36481761932373,
      "min_reward": 3.1512014865875244,
      "std_reward": 1.0060865879058838,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2448
    },
    {
      "iteration": 234,
      "timesteps": 731664,
      "mean_reward": 6.132567405700684,
      "max_reward": 9.409290313720703,
      "min_reward": 2.8906490802764893,
      "std_reward": 1.342883825302124,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2416
    },
    {
      "iteration": 235,
      "timesteps": 734481,
      "mean_reward": 7.021044731140137,
      "max_reward": 9.545772552490234,
      "min_reward": 5.158329010009766,
      "std_reward": 1.0162065029144287,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2817
    },
    {
      "iteration": 236,
      "timesteps": 737177,
      "mean_reward": 6.569204807281494,
      "max_reward": 9.20221996307373,
      "min_reward": 2.7703745365142822,
      "std_reward": 1.3622708320617676,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2696
    },
    {
      "iteration": 237,
      "timesteps": 739333,
      "mean_reward": 6.344902515411377,
      "max_reward": 9.00549030303955,
      "min_reward": 3.170379877090454,
      "std_reward": 1.3202929496765137,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2156
    },
    {
      "iteration": 238,
      "timesteps": 741833,
      "mean_reward": 6.371338367462158,
      "max_reward": 9.86352825164795,
      "min_reward": 3.5032033920288086,
      "std_reward": 1.4707666635513306,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2500
    },
    {
      "iteration": 239,
      "timesteps": 744128,
      "mean_reward": 6.440814018249512,
      "max_reward": 9.294534683227539,
      "min_reward": 2.9006619453430176,
      "std_reward": 1.560487985610962,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2295
    },
    {
      "iteration": 240,
      "timesteps": 747004,
      "mean_reward": 7.041191101074219,
      "max_reward": 12.398365020751953,
      "min_reward": 4.609524726867676,
      "std_reward": 1.4397203922271729,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2876
    },
    {
      "iteration": 241,
      "timesteps": 749902,
      "mean_reward": 5.592146396636963,
      "max_reward": 9.626791954040527,
      "min_reward": 2.523146152496338,
      "std_reward": 1.8478907346725464,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2898
    },
    {
      "iteration": 242,
      "timesteps": 752357,
      "mean_reward": 5.811379432678223,
      "max_reward": 8.63328742980957,
      "min_reward": 2.1700241565704346,
      "std_reward": 1.590475082397461,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2455
    },
    {
      "iteration": 243,
      "timesteps": 755005,
      "mean_reward": 6.842089653015137,
      "max_reward": 9.202136039733887,
      "min_reward": 4.6912126541137695,
      "std_reward": 1.1036134958267212,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2648
    },
    {
      "iteration": 244,
      "timesteps": 757855,
      "mean_reward": 6.536772727966309,
      "max_reward": 11.769551277160645,
      "min_reward": 4.624917984008789,
      "std_reward": 1.4114760160446167,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2850
    },
    {
      "iteration": 245,
      "timesteps": 760113,
      "mean_reward": 6.943068027496338,
      "max_reward": 9.252800941467285,
      "min_reward": 3.0995824337005615,
      "std_reward": 1.2763793468475342,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2258
    },
    {
      "iteration": 246,
      "timesteps": 762598,
      "mean_reward": 6.724224090576172,
      "max_reward": 9.123425483703613,
      "min_reward": 4.049831867218018,
      "std_reward": 1.1574290990829468,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2485
    },
    {
      "iteration": 247,
      "timesteps": 764835,
      "mean_reward": 6.954978942871094,
      "max_reward": 9.841540336608887,
      "min_reward": 4.264214038848877,
      "std_reward": 1.2485990524291992,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2237
    },
    {
      "iteration": 248,
      "timesteps": 767396,
      "mean_reward": 6.7884345054626465,
      "max_reward": 9.039755821228027,
      "min_reward": 4.338758945465088,
      "std_reward": 1.0167876482009888,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2561
    },
    {
      "iteration": 249,
      "timesteps": 769505,
      "mean_reward": 7.102480888366699,
      "max_reward": 9.194915771484375,
      "min_reward": 5.493871688842773,
      "std_reward": 0.7912526726722717,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2109
    },
    {
      "iteration": 250,
      "timesteps": 772669,
      "mean_reward": 6.746441841125488,
      "max_reward": 9.831851959228516,
      "min_reward": 3.731081247329712,
      "std_reward": 1.4218502044677734,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3164
    },
    {
      "iteration": 251,
      "timesteps": 774666,
      "mean_reward": 6.980729579925537,
      "max_reward": 9.349461555480957,
      "min_reward": 4.654970645904541,
      "std_reward": 1.2209306955337524,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 1997
    },
    {
      "iteration": 252,
      "timesteps": 776537,
      "mean_reward": 6.405299186706543,
      "max_reward": 9.011908531188965,
      "min_reward": 3.230192184448242,
      "std_reward": 1.2822296619415283,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 1871
    },
    {
      "iteration": 253,
      "timesteps": 778730,
      "mean_reward": 7.32531213760376,
      "max_reward": 9.265758514404297,
      "min_reward": 2.9681246280670166,
      "std_reward": 1.201862096786499,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2193
    },
    {
      "iteration": 254,
      "timesteps": 780666,
      "mean_reward": 7.4759521484375,
      "max_reward": 18.088088989257812,
      "min_reward": 2.931866407394409,
      "std_reward": 2.6604833602905273,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 1936
    },
    {
      "iteration": 255,
      "timesteps": 782854,
      "mean_reward": 6.538692474365234,
      "max_reward": 9.140130043029785,
      "min_reward": 2.739274740219116,
      "std_reward": 1.5540261268615723,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2188
    },
    {
      "iteration": 256,
      "timesteps": 784937,
      "mean_reward": 7.1496710777282715,
      "max_reward": 10.604645729064941,
      "min_reward": 3.8498432636260986,
      "std_reward": 1.0682575702667236,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2083
    },
    {
      "iteration": 257,
      "timesteps": 787270,
      "mean_reward": 7.00198221206665,
      "max_reward": 9.498324394226074,
      "min_reward": 2.916750431060791,
      "std_reward": 1.2457163333892822,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2333
    },
    {
      "iteration": 258,
      "timesteps": 789405,
      "mean_reward": 6.792679786682129,
      "max_reward": 9.762550354003906,
      "min_reward": 3.308717966079712,
      "std_reward": 1.2255254983901978,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2135
    },
    {
      "iteration": 259,
      "timesteps": 791590,
      "mean_reward": 6.989053249359131,
      "max_reward": 8.926651954650879,
      "min_reward": 4.877444744110107,
      "std_reward": 1.0434596538543701,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2185
    },
    {
      "iteration": 260,
      "timesteps": 793920,
      "mean_reward": 7.2335524559021,
      "max_reward": 13.604969024658203,
      "min_reward": 4.645623683929443,
      "std_reward": 1.4945615530014038,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2330
    },
    {
      "iteration": 261,
      "timesteps": 795968,
      "mean_reward": 6.765000820159912,
      "max_reward": 8.493627548217773,
      "min_reward": 5.27262020111084,
      "std_reward": 0.8222877979278564,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2048
    },
    {
      "iteration": 262,
      "timesteps": 798744,
      "mean_reward": 7.209758758544922,
      "max_reward": 16.679784774780273,
      "min_reward": 3.9311673641204834,
      "std_reward": 2.1849148273468018,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2776
    },
    {
      "iteration": 263,
      "timesteps": 801450,
      "mean_reward": 6.512940406799316,
      "max_reward": 15.059231758117676,
      "min_reward": 3.4226677417755127,
      "std_reward": 2.4450063705444336,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2706
    },
    {
      "iteration": 264,
      "timesteps": 804557,
      "mean_reward": 6.694927215576172,
      "max_reward": 11.849078178405762,
      "min_reward": 4.540059566497803,
      "std_reward": 1.6175786256790161,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3107
    },
    {
      "iteration": 265,
      "timesteps": 807350,
      "mean_reward": 7.471135139465332,
      "max_reward": 13.36413860321045,
      "min_reward": 4.83463716506958,
      "std_reward": 1.81582772731781,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2793
    },
    {
      "iteration": 266,
      "timesteps": 810321,
      "mean_reward": 7.087289333343506,
      "max_reward": 8.726883888244629,
      "min_reward": 5.6963653564453125,
      "std_reward": 0.7871314883232117,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2971
    },
    {
      "iteration": 267,
      "timesteps": 812612,
      "mean_reward": 7.3709306716918945,
      "max_reward": 10.246133804321289,
      "min_reward": 5.5781683921813965,
      "std_reward": 1.066982626914978,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2291
    },
    {
      "iteration": 268,
      "timesteps": 815188,
      "mean_reward": 7.919874668121338,
      "max_reward": 15.673595428466797,
      "min_reward": 5.646866798400879,
      "std_reward": 1.5919249057769775,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2576
    },
    {
      "iteration": 269,
      "timesteps": 817356,
      "mean_reward": 7.958532810211182,
      "max_reward": 15.534723281860352,
      "min_reward": 4.721550941467285,
      "std_reward": 1.682894229888916,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2168
    },
    {
      "iteration": 270,
      "timesteps": 820181,
      "mean_reward": 7.576647758483887,
      "max_reward": 10.109552383422852,
      "min_reward": 5.563114166259766,
      "std_reward": 1.1281036138534546,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2825
    },
    {
      "iteration": 271,
      "timesteps": 822994,
      "mean_reward": 7.521066188812256,
      "max_reward": 13.431344985961914,
      "min_reward": 4.287661075592041,
      "std_reward": 1.6246682405471802,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2813
    },
    {
      "iteration": 272,
      "timesteps": 825338,
      "mean_reward": 7.605006217956543,
      "max_reward": 10.948229789733887,
      "min_reward": 5.386834144592285,
      "std_reward": 1.1561659574508667,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2344
    },
    {
      "iteration": 273,
      "timesteps": 828084,
      "mean_reward": 7.530767917633057,
      "max_reward": 9.585174560546875,
      "min_reward": 5.362459182739258,
      "std_reward": 1.0707045793533325,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2746
    },
    {
      "iteration": 274,
      "timesteps": 831134,
      "mean_reward": 7.614189147949219,
      "max_reward": 16.559133529663086,
      "min_reward": 3.4568989276885986,
      "std_reward": 2.736799716949463,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3050
    },
    {
      "iteration": 275,
      "timesteps": 833539,
      "mean_reward": 8.372215270996094,
      "max_reward": 29.023191452026367,
      "min_reward": 5.419879913330078,
      "std_reward": 3.9126763343811035,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2405
    },
    {
      "iteration": 276,
      "timesteps": 836109,
      "mean_reward": 7.1942949295043945,
      "max_reward": 11.6159029006958,
      "min_reward": 4.115954399108887,
      "std_reward": 1.4427180290222168,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2570
    },
    {
      "iteration": 277,
      "timesteps": 839007,
      "mean_reward": 7.796250820159912,
      "max_reward": 17.03397560119629,
      "min_reward": 4.462936878204346,
      "std_reward": 1.9803985357284546,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2898
    },
    {
      "iteration": 278,
      "timesteps": 841475,
      "mean_reward": 7.9699506759643555,
      "max_reward": 13.744325637817383,
      "min_reward": 4.895833969116211,
      "std_reward": 1.7408608198165894,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2468
    },
    {
      "iteration": 279,
      "timesteps": 843960,
      "mean_reward": 7.607832431793213,
      "max_reward": 19.37339973449707,
      "min_reward": 3.5502254962921143,
      "std_reward": 2.5389297008514404,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2485
    },
    {
      "iteration": 280,
      "timesteps": 846573,
      "mean_reward": 7.895617485046387,
      "max_reward": 13.795814514160156,
      "min_reward": 4.330657005310059,
      "std_reward": 1.6038771867752075,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2613
    },
    {
      "iteration": 281,
      "timesteps": 849352,
      "mean_reward": 8.20849609375,
      "max_reward": 12.024663925170898,
      "min_reward": 6.075026512145996,
      "std_reward": 1.2085102796554565,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2779
    },
    {
      "iteration": 282,
      "timesteps": 851734,
      "mean_reward": 8.265560150146484,
      "max_reward": 14.74215030670166,
      "min_reward": 6.423228740692139,
      "std_reward": 1.6315360069274902,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2382
    },
    {
      "iteration": 283,
      "timesteps": 853761,
      "mean_reward": 7.735024929046631,
      "max_reward": 10.977352142333984,
      "min_reward": 5.190912246704102,
      "std_reward": 1.0382354259490967,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2027
    },
    {
      "iteration": 284,
      "timesteps": 856070,
      "mean_reward": 7.904314994812012,
      "max_reward": 10.312507629394531,
      "min_reward": 5.542026996612549,
      "std_reward": 1.0952482223510742,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2309
    },
    {
      "iteration": 285,
      "timesteps": 858625,
      "mean_reward": 8.440252304077148,
      "max_reward": 17.432340621948242,
      "min_reward": 6.174407005310059,
      "std_reward": 1.7749872207641602,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2555
    },
    {
      "iteration": 286,
      "timesteps": 861316,
      "mean_reward": 8.017570495605469,
      "max_reward": 11.175037384033203,
      "min_reward": 5.7458672523498535,
      "std_reward": 1.0502235889434814,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2691
    },
    {
      "iteration": 287,
      "timesteps": 864738,
      "mean_reward": 6.9186506271362305,
      "max_reward": 9.556107521057129,
      "min_reward": 2.7837576866149902,
      "std_reward": 1.6290843486785889,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3422
    },
    {
      "iteration": 288,
      "timesteps": 867317,
      "mean_reward": 7.609367370605469,
      "max_reward": 10.72436237335205,
      "min_reward": 6.195051670074463,
      "std_reward": 1.1614409685134888,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2579
    },
    {
      "iteration": 289,
      "timesteps": 870089,
      "mean_reward": 8.007939338684082,
      "max_reward": 13.424575805664062,
      "min_reward": 3.704923152923584,
      "std_reward": 1.8131905794143677,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2772
    },
    {
      "iteration": 290,
      "timesteps": 872730,
      "mean_reward": 8.260665893554688,
      "max_reward": 12.618124961853027,
      "min_reward": 5.793683052062988,
      "std_reward": 1.407431960105896,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2641
    },
    {
      "iteration": 291,
      "timesteps": 875789,
      "mean_reward": 8.454399108886719,
      "max_reward": 24.30446434020996,
      "min_reward": 3.295762300491333,
      "std_reward": 2.9040427207946777,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 3059
    },
    {
      "iteration": 292,
      "timesteps": 878075,
      "mean_reward": 7.7949628829956055,
      "max_reward": 12.254233360290527,
      "min_reward": 5.199015140533447,
      "std_reward": 1.2563676834106445,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2286
    },
    {
      "iteration": 293,
      "timesteps": 880643,
      "mean_reward": 8.298933029174805,
      "max_reward": 15.224705696105957,
      "min_reward": 5.361588001251221,
      "std_reward": 1.8725181818008423,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2568
    },
    {
      "iteration": 294,
      "timesteps": 883390,
      "mean_reward": 8.345405578613281,
      "max_reward": 17.463302612304688,
      "min_reward": 5.312631130218506,
      "std_reward": 2.0586845874786377,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2747
    },
    {
      "iteration": 295,
      "timesteps": 885580,
      "mean_reward": 7.804272651672363,
      "max_reward": 12.259172439575195,
      "min_reward": 5.489552974700928,
      "std_reward": 1.3116730451583862,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2190
    },
    {
      "iteration": 296,
      "timesteps": 888366,
      "mean_reward": 8.0423583984375,
      "max_reward": 15.110546112060547,
      "min_reward": 5.161628723144531,
      "std_reward": 1.937766432762146,
      "best_reward": 8.748918533325195,
      "episodes": 40,
      "steps_this_iter": 2786
    },
    {
      "iteration": 297,
      "timesteps": 891016,
      "mean_reward": 8.955113410949707,
      "max_reward": 23.126142501831055,
      "min_reward": 6.39858341217041,
      "std_reward": 2.8229377269744873,
      "best_reward": 8.955113410949707,
      "episodes": 40,
      "steps_this_iter": 2650
    },
    {
      "iteration": 298,
      "timesteps": 893415,
      "mean_reward": 7.922536373138428,
      "max_reward": 13.338155746459961,
      "min_reward": 4.580330848693848,
      "std_reward": 1.3743395805358887,
      "best_reward": 8.955113410949707,
      "episodes": 40,
      "steps_this_iter": 2399
    },
    {
      "iteration": 299,
      "timesteps": 896164,
      "mean_reward": 7.882038116455078,
      "max_reward": 15.803999900817871,
      "min_reward": 5.1191792488098145,
      "std_reward": 1.801418423652649,
      "best_reward": 8.955113410949707,
      "episodes": 40,
      "steps_this_iter": 2749
    },
    {
      "iteration": 300,
      "timesteps": 899173,
      "mean_reward": 7.867225646972656,
      "max_reward": 11.289860725402832,
      "min_reward": 4.6971049308776855,
      "std_reward": 1.5061770677566528,
      "best_reward": 8.955113410949707,
      "episodes": 40,
      "steps_this_iter": 3009
    },
    {
      "iteration": 301,
      "timesteps": 901650,
      "mean_reward": 7.951574802398682,
      "max_reward": 11.041333198547363,
      "min_reward": 5.480387210845947,
      "std_reward": 1.1814780235290527,
      "best_reward": 8.955113410949707,
      "episodes": 40,
      "steps_this_iter": 2477
    },
    {
      "iteration": 302,
      "timesteps": 904711,
      "mean_reward": 8.468066215515137,
      "max_reward": 18.543628692626953,
      "min_reward": 3.913783550262451,
      "std_reward": 2.44692063331604,
      "best_reward": 8.955113410949707,
      "episodes": 40,
      "steps_this_iter": 3061
    },
    {
      "iteration": 303,
      "timesteps": 907438,
      "mean_reward": 8.202573776245117,
      "max_reward": 14.268781661987305,
      "min_reward": 4.704453468322754,
      "std_reward": 1.6766026020050049,
      "best_reward": 8.955113410949707,
      "episodes": 40,
      "steps_this_iter": 2727
    },
    {
      "iteration": 304,
      "timesteps": 910125,
      "mean_reward": 8.396549224853516,
      "max_reward": 11.739995956420898,
      "min_reward": 5.11824369430542,
      "std_reward": 1.3453158140182495,
      "best_reward": 8.955113410949707,
      "episodes": 40,
      "steps_this_iter": 2687
    },
    {
      "iteration": 305,
      "timesteps": 912722,
      "mean_reward": 8.726956367492676,
      "max_reward": 20.122068405151367,
      "min_reward": 5.9846882820129395,
      "std_reward": 2.2573509216308594,
      "best_reward": 8.955113410949707,
      "episodes": 40,
      "steps_this_iter": 2597
    },
    {
      "iteration": 306,
      "timesteps": 915738,
      "mean_reward": 9.02942180633545,
      "max_reward": 16.047086715698242,
      "min_reward": 6.518172264099121,
      "std_reward": 1.8859202861785889,
      "best_reward": 9.02942180633545,
      "episodes": 40,
      "steps_this_iter": 3016
    },
    {
      "iteration": 307,
      "timesteps": 918409,
      "mean_reward": 7.749083042144775,
      "max_reward": 14.242229461669922,
      "min_reward": 4.0168280601501465,
      "std_reward": 1.719379186630249,
      "best_reward": 9.02942180633545,
      "episodes": 40,
      "steps_this_iter": 2671
    },
    {
      "iteration": 308,
      "timesteps": 921067,
      "mean_reward": 7.993622779846191,
      "max_reward": 11.911723136901855,
      "min_reward": 5.18078088760376,
      "std_reward": 1.331824779510498,
      "best_reward": 9.02942180633545,
      "episodes": 40,
      "steps_this_iter": 2658
    },
    {
      "iteration": 309,
      "timesteps": 923310,
      "mean_reward": 8.046350479125977,
      "max_reward": 12.720205307006836,
      "min_reward": 4.938209533691406,
      "std_reward": 1.408833384513855,
      "best_reward": 9.02942180633545,
      "episodes": 40,
      "steps_this_iter": 2243
    },
    {
      "iteration": 310,
      "timesteps": 926171,
      "mean_reward": 7.6064605712890625,
      "max_reward": 10.328411102294922,
      "min_reward": 3.498713493347168,
      "std_reward": 1.266857385635376,
      "best_reward": 9.02942180633545,
      "episodes": 40,
      "steps_this_iter": 2861
    },
    {
      "iteration": 311,
      "timesteps": 928456,
      "mean_reward": 6.828707695007324,
      "max_reward": 8.908103942871094,
      "min_reward": 4.054154396057129,
      "std_reward": 0.935817301273346,
      "best_reward": 9.02942180633545,
      "episodes": 40,
      "steps_this_iter": 2285
    },
    {
      "iteration": 312,
      "timesteps": 930945,
      "mean_reward": 6.930643558502197,
      "max_reward": 11.306373596191406,
      "min_reward": 3.6058735847473145,
      "std_reward": 1.4004669189453125,
      "best_reward": 9.02942180633545,
      "episodes": 40,
      "steps_this_iter": 2489
    },
    {
      "iteration": 313,
      "timesteps": 933510,
      "mean_reward": 6.678231239318848,
      "max_reward": 10.6751127243042,
      "min_reward": 2.519301652908325,
      "std_reward": 1.8246372938156128,
      "best_reward": 9.02942180633545,
      "episodes": 40,
      "steps_this_iter": 2565
    },
    {
      "iteration": 314,
      "timesteps": 935803,
      "mean_reward": 7.305088996887207,
      "max_reward": 11.506195068359375,
      "min_reward": 3.3887388706207275,
      "std_reward": 1.8637722730636597,
      "best_reward": 9.02942180633545,
      "episodes": 40,
      "steps_this_iter": 2293
    },
    {
      "iteration": 315,
      "timesteps": 938448,
      "mean_reward": 7.854531764984131,
      "max_reward": 14.298101425170898,
      "min_reward": 4.688464641571045,
      "std_reward": 2.042576551437378,
      "best_reward": 9.02942180633545,
      "episodes": 40,
      "steps_this_iter": 2645
    },
    {
      "iteration": 316,
      "timesteps": 941163,
      "mean_reward": 7.715750217437744,
      "max_reward": 16.539308547973633,
      "min_reward": 3.6894991397857666,
      "std_reward": 2.1804609298706055,
      "best_reward": 9.02942180633545,
      "episodes": 40,
      "steps_this_iter": 2715
    },
    {
      "iteration": 317,
      "timesteps": 943669,
      "mean_reward": 7.501143455505371,
      "max_reward": 14.941571235656738,
      "min_reward": 4.630463123321533,
      "std_reward": 2.0558338165283203,
      "best_reward": 9.02942180633545,
      "episodes": 40,
      "steps_this_iter": 2506
    },
    {
      "iteration": 318,
      "timesteps": 946706,
      "mean_reward": 7.514996528625488,
      "max_reward": 10.282109260559082,
      "min_reward": 4.90161657333374,
      "std_reward": 1.319851040840149,
      "best_reward": 9.02942180633545,
      "episodes": 40,
      "steps_this_iter": 3037
    },
    {
      "iteration": 319,
      "timesteps": 949439,
      "mean_reward": 7.124180793762207,
      "max_reward": 10.692586898803711,
      "min_reward": 4.24350118637085,
      "std_reward": 1.34036123752594,
      "best_reward": 9.02942180633545,
      "episodes": 40,
      "steps_this_iter": 2733
    },
    {
      "iteration": 320,
      "timesteps": 952242,
      "mean_reward": 7.562477111816406,
      "max_reward": 11.270124435424805,
      "min_reward": 2.876641035079956,
      "std_reward": 1.5713872909545898,
      "best_reward": 9.02942180633545,
      "episodes": 40,
      "steps_this_iter": 2803
    },
    {
      "iteration": 321,
      "timesteps": 954899,
      "mean_reward": 7.417714595794678,
      "max_reward": 10.01393985748291,
      "min_reward": 5.006837368011475,
      "std_reward": 1.158187747001648,
      "best_reward": 9.02942180633545,
      "episodes": 40,
      "steps_this_iter": 2657
    },
    {
      "iteration": 322,
      "timesteps": 957115,
      "mean_reward": 6.893214225769043,
      "max_reward": 19.07442855834961,
      "min_reward": 2.7789576053619385,
      "std_reward": 2.452350378036499,
      "best_reward": 9.02942180633545,
      "episodes": 40,
      "steps_this_iter": 2216
    },
    {
      "iteration": 323,
      "timesteps": 959435,
      "mean_reward": 6.446162223815918,
      "max_reward": 9.212311744689941,
      "min_reward": 3.5267903804779053,
      "std_reward": 1.2766304016113281,
      "best_reward": 9.02942180633545,
      "episodes": 40,
      "steps_this_iter": 2320
    },
    {
      "iteration": 324,
      "timesteps": 961890,
      "mean_reward": 7.069132328033447,
      "max_reward": 11.287548065185547,
      "min_reward": 3.314837694168091,
      "std_reward": 1.8380603790283203,
      "best_reward": 9.02942180633545,
      "episodes": 40,
      "steps_this_iter": 2455
    },
    {
      "iteration": 325,
      "timesteps": 964693,
      "mean_reward": 7.654226779937744,
      "max_reward": 11.763224601745605,
      "min_reward": 4.087820529937744,
      "std_reward": 1.6643916368484497,
      "best_reward": 9.02942180633545,
      "episodes": 40,
      "steps_this_iter": 2803
    },
    {
      "iteration": 326,
      "timesteps": 967396,
      "mean_reward": 7.969666481018066,
      "max_reward": 12.508240699768066,
      "min_reward": 3.5962042808532715,
      "std_reward": 2.3929293155670166,
      "best_reward": 9.02942180633545,
      "episodes": 40,
      "steps_this_iter": 2703
    },
    {
      "iteration": 327,
      "timesteps": 969915,
      "mean_reward": 7.252204895019531,
      "max_reward": 10.854522705078125,
      "min_reward": 4.060107231140137,
      "std_reward": 1.4731247425079346,
      "best_reward": 9.02942180633545,
      "episodes": 40,
      "steps_this_iter": 2519
    },
    {
      "iteration": 328,
      "timesteps": 972758,
      "mean_reward": 8.081706047058105,
      "max_reward": 14.742191314697266,
      "min_reward": 3.706643581390381,
      "std_reward": 2.468733310699463,
      "best_reward": 9.02942180633545,
      "episodes": 40,
      "steps_this_iter": 2843
    },
    {
      "iteration": 329,
      "timesteps": 975490,
      "mean_reward": 7.519383907318115,
      "max_reward": 18.96377944946289,
      "min_reward": 2.3001091480255127,
      "std_reward": 2.6382181644439697,
      "best_reward": 9.02942180633545,
      "episodes": 40,
      "steps_this_iter": 2732
    },
    {
      "iteration": 330,
      "timesteps": 978230,
      "mean_reward": 7.519576072692871,
      "max_reward": 14.822924613952637,
      "min_reward": 3.734281063079834,
      "std_reward": 2.0927162170410156,
      "best_reward": 9.02942180633545,
      "episodes": 40,
      "steps_this_iter": 2740
    },
    {
      "iteration": 331,
      "timesteps": 980980,
      "mean_reward": 7.709233283996582,
      "max_reward": 14.545631408691406,
      "min_reward": 3.5602715015411377,
      "std_reward": 2.362318992614746,
      "best_reward": 9.02942180633545,
      "episodes": 40,
      "steps_this_iter": 2750
    },
    {
      "iteration": 332,
      "timesteps": 984056,
      "mean_reward": 7.252648830413818,
      "max_reward": 12.004727363586426,
      "min_reward": 2.4002223014831543,
      "std_reward": 2.270094156265259,
      "best_reward": 9.02942180633545,
      "episodes": 40,
      "steps_this_iter": 3076
    },
    {
      "iteration": 333,
      "timesteps": 986365,
      "mean_reward": 7.027459144592285,
      "max_reward": 10.940509796142578,
      "min_reward": 4.017760276794434,
      "std_reward": 1.2764427661895752,
      "best_reward": 9.02942180633545,
      "episodes": 40,
      "steps_this_iter": 2309
    },
    {
      "iteration": 334,
      "timesteps": 989318,
      "mean_reward": 8.938773155212402,
      "max_reward": 22.237632751464844,
      "min_reward": 4.096603870391846,
      "std_reward": 3.7986366748809814,
      "best_reward": 9.02942180633545,
      "episodes": 40,
      "steps_this_iter": 2953
    },
    {
      "iteration": 335,
      "timesteps": 992700,
      "mean_reward": 8.327433586120605,
      "max_reward": 17.370038986206055,
      "min_reward": 3.895826816558838,
      "std_reward": 2.9600470066070557,
      "best_reward": 9.02942180633545,
      "episodes": 40,
      "steps_this_iter": 3382
    },
    {
      "iteration": 336,
      "timesteps": 995514,
      "mean_reward": 8.748920440673828,
      "max_reward": 14.617423057556152,
      "min_reward": 3.901714563369751,
      "std_reward": 2.873016119003296,
      "best_reward": 9.02942180633545,
      "episodes": 40,
      "steps_this_iter": 2814
    },
    {
      "iteration": 337,
      "timesteps": 998450,
      "mean_reward": 7.6667327880859375,
      "max_reward": 11.961423873901367,
      "min_reward": 3.149336814880371,
      "std_reward": 2.2857584953308105,
      "best_reward": 9.02942180633545,
      "episodes": 40,
      "steps_this_iter": 2936
    },
    {
      "iteration": 338,
      "timesteps": 1001551,
      "mean_reward": 9.042348861694336,
      "max_reward": 22.394105911254883,
      "min_reward": 3.5441794395446777,
      "std_reward": 3.547273635864258,
      "best_reward": 9.042348861694336,
      "episodes": 40,
      "steps_this_iter": 3101
    }
  ],
  "eval_history": [
    {
      "iteration": 50,
      "timesteps": 158173,
      "eval_reward": 9.928592588323301
    },
    {
      "iteration": 100,
      "timesteps": 323332,
      "eval_reward": 8.079374121591
    },
    {
      "iteration": 150,
      "timesteps": 473342,
      "eval_reward": 6.443576419475664
    },
    {
      "iteration": 200,
      "timesteps": 642298,
      "eval_reward": 6.010597574912393
    },
    {
      "iteration": 250,
      "timesteps": 772669,
      "eval_reward": 7.685658553470173
    },
    {
      "iteration": 300,
      "timesteps": 899173,
      "eval_reward": 7.303765588441777
    }
  ]
}